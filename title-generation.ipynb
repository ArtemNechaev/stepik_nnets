{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/ArtemNechaev/stepik_nnets/blob/main/task8_translate_de2en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"code","source":"!git clone https://github.com/ArtemNechaev/stepik_nnets ","metadata":{"id":"HmgOOdMD3AmR","outputId":"e39c6e16-6ec9-4457-b34b-a516c2f5197b","execution":{"iopub.status.busy":"2022-04-27T03:29:38.189459Z","iopub.execute_input":"2022-04-27T03:29:38.189761Z","iopub.status.idle":"2022-04-27T03:29:40.735793Z","shell.execute_reply.started":"2022-04-27T03:29:38.189677Z","shell.execute_reply":"2022-04-27T03:29:40.734914Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'stepik_nnets'...\nremote: Enumerating objects: 129, done.\u001b[K\nremote: Counting objects: 100% (129/129), done.\u001b[K\nremote: Compressing objects: 100% (98/98), done.\u001b[K\nremote: Total 129 (delta 56), reused 68 (delta 24), pack-reused 0\u001b[K\nReceiving objects: 100% (129/129), 2.37 MiB | 2.76 MiB/s, done.\nResolving deltas: 100% (56/56), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\n\nfrom collections import OrderedDict, Counter\n\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator, FastText, vocab\nfrom torchtext.datasets import Multi30k\nfrom typing import Iterable, List\n\nfrom stepik_nnets.sec2sec.data import Sec2SecDataset, sequential_transforms, TensorTransform, myFastText\nfrom stepik_nnets.sec2sec.models.only_gru import OnlyGRU \n\nfrom stepik_nnets.sec2sec.engine import train, evaluate, predict_with_model, data_to_device\n#from stepik_nnets.sec2sec.beam_search import  beam_search_rnn\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\nimport spacy\n\nimport random\nimport math\nimport time\nfrom tqdm import tqdm\nimport pickle\n\nimport zipfile\n#import gensim\n","metadata":{"id":"6dneov4I9enW","outputId":"ac4780f6-70dd-435c-c474-0855d114cbad","execution":{"iopub.status.busy":"2022-04-27T04:38:01.381137Z","iopub.execute_input":"2022-04-27T04:38:01.381427Z","iopub.status.idle":"2022-04-27T04:38:01.416211Z","shell.execute_reply.started":"2022-04-27T04:38:01.381394Z","shell.execute_reply":"2022-04-27T04:38:01.415172Z"},"trusted":true},"execution_count":45,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34/657790117.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstepik_nnets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msec2sec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_with_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_to_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstepik_nnets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msec2sec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam_search\u001b[0m \u001b[0;32mimport\u001b[0m  \u001b[0mbeam_search_rnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stepik_nnets.sec2sec.beam_search'"],"ename":"ModuleNotFoundError","evalue":"No module named 'stepik_nnets.sec2sec.beam_search'","output_type":"error"}]},{"cell_type":"code","source":"SEED = 0\npretrained_embed = False\n\n\nrandom.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"id":"LonnFFNd9enX","execution":{"iopub.status.busy":"2022-04-27T03:41:21.510582Z","iopub.execute_input":"2022-04-27T03:41:21.511063Z","iopub.status.idle":"2022-04-27T03:41:21.523897Z","shell.execute_reply.started":"2022-04-27T03:41:21.511010Z","shell.execute_reply":"2022-04-27T03:41:21.522812Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/title-generation/train.csv')\n_, all = zip(*df.iterrows())\nall = list(all)\nTRAIN_SPLIT = int(len(all) * 0.9)\nnp.random.shuffle(all)\ntrain_iter = all[:TRAIN_SPLIT]\nval_iter = all[TRAIN_SPLIT:]\nall = None\n","metadata":{"execution":{"iopub.status.busy":"2022-04-27T03:30:35.418769Z","iopub.execute_input":"2022-04-27T03:30:35.419032Z","iopub.status.idle":"2022-04-27T03:30:48.687430Z","shell.execute_reply.started":"2022-04-27T03:30:35.419002Z","shell.execute_reply":"2022-04-27T03:30:48.686627Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import re\n\n\nTOKEN_RE = re.compile(r'[\\w\\d]+')\n\ndef tokenize_text_simple_regex(txt, min_token_size=1):\n    txt = txt.lower()\n    all_tokens = TOKEN_RE.findall(txt)\n    return [token for token in all_tokens if len(token) >= min_token_size]","metadata":{"id":"tzyfOrAPFh3d","execution":{"iopub.status.busy":"2022-04-27T03:30:48.688950Z","iopub.execute_input":"2022-04-27T03:30:48.689235Z","iopub.status.idle":"2022-04-27T03:30:48.696416Z","shell.execute_reply.started":"2022-04-27T03:30:48.689197Z","shell.execute_reply":"2022-04-27T03:30:48.695505Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\nSRC_LANGUAGE = 'abs'\nTGT_LANGUAGE = 'title'\n\nln_pair = (SRC_LANGUAGE, TGT_LANGUAGE)\n\n# Place-holders\ntoken_transform = {}\nvocab_transform = {}\n\n\n# Create source and target language tokenizer. Make sure to install the dependencies.\n\ntoken_transform[TGT_LANGUAGE] = tokenize_text_simple_regex#get_tokenizer('spacy', language='en_core_web_lg')\ntoken_transform[SRC_LANGUAGE] = tokenize_text_simple_regex#get_tokenizer('spacy', language='en_core_web_lg')\n\n\n# Define special symbols and indices\nUNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n# Make sure the tokens are in order of their indices to properly insert them in vocab\nspecial_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n\n\ntokenized_train = ((token_transform[SRC_LANGUAGE](t[0]) , token_transform[TGT_LANGUAGE](t[1]))\n    for t in train_iter)\n\ntrain_iter_src, train_iter_trg = zip(*tokenized_train)\n\n\nif pretrained_embed:\n  ft_embed = myFastText(language='en')\n  s_dict = {s:i for i, s in enumerate( special_symbols)} \n  ft_embed.stoi = { w: i for i, (w, _) in  enumerate(list(s_dict.items()) + list(ft_embed.stoi.items()))}\n  vocab_transform[SRC_LANGUAGE] = vocab(ft_embed.stoi, min_freq=0)\nelse:\n  vocab_transform[SRC_LANGUAGE] = build_vocab_from_iterator(train_iter_src,\n                                                      min_freq=1,\n                                                      specials=special_symbols,\n                                                      special_first=True)\n\nvocab_transform[TGT_LANGUAGE] = vocab_transform[SRC_LANGUAGE]\n\n\n\n    # Set UNK_IDX as the default index. This index is returned when the token is not found.\n    # If not set, it throws RuntimeError when the queried token is not found in the Vocabulary.\n\nvocab_transform[SRC_LANGUAGE].set_default_index(UNK_IDX)\nvocab_transform[TGT_LANGUAGE].set_default_index(UNK_IDX)\n\n\n# src and tgt language text transforms to convert raw strings into tensors indices\ntext_transform = {}\nfor ln in ln_pair:\n    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n                                               vocab_transform[ln], #Numericalization\n                                               TensorTransform(BOS_IDX, EOS_IDX)) # Add BOS/EOS and create tensor\n\n","metadata":{"id":"Kc8Of-j_Qr6f","outputId":"02e0347a-9307-44cf-8e61-ecb8f677f54a","execution":{"iopub.status.busy":"2022-04-27T03:33:48.292394Z","iopub.execute_input":"2022-04-27T03:33:48.292970Z","iopub.status.idle":"2022-04-27T03:35:18.331770Z","shell.execute_reply.started":"2022-04-27T03:33:48.292929Z","shell.execute_reply":"2022-04-27T03:35:18.330930Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_dataset = Sec2SecDataset( train_iter, text_transform, PAD_IDX, ln_pair = ln_pair)\ntrain_iterator = DataLoader(train_dataset, batch_size=30, shuffle = True, collate_fn = train_dataset.pad_collate_fn)\n\nval_dataset = Sec2SecDataset( val_iter, text_transform, PAD_IDX, ln_pair = ln_pair)\nvalid_iterator = DataLoader(val_dataset, batch_size=30, collate_fn = train_dataset.pad_collate_fn)","metadata":{"id":"z87CSNWgFh3h","outputId":"e4de8947-7104-406e-c240-d8dcb8382aab","execution":{"iopub.status.busy":"2022-04-27T03:36:33.671213Z","iopub.execute_input":"2022-04-27T03:36:33.671482Z","iopub.status.idle":"2022-04-27T03:37:45.666113Z","shell.execute_reply.started":"2022-04-27T03:36:33.671439Z","shell.execute_reply":"2022-04-27T03:37:45.665367Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#tgt_stoi = vocab_transform[TGT_LANGUAGE].get_stoi()\n#src2trg = torch.zeros(len(vocab_transform[SRC_LANGUAGE]), dtype=torch.long, device = device)\n#for w, i in tqdm(vocab_transform[SRC_LANGUAGE].get_stoi().items()):\n    #src2trg[i] = tgt_stoi.get(w, 0)\n\nclass Model(OnlyGRU):\n    def __init__(self, *args, **kwargs ):\n        super().__init__(*args, **kwargs)\n        \n    def forward(self, src, trg, teacher_forcing_ratio, *args):\n        outputs = super().forward(src, trg, teacher_forcing_ratio, *args)\n        mask = torch.zeros(outputs.shape, device=self.device , dtype = torch.float)\n        mask += 0.3\n        for b in range(mask.shape[1]):\n            mask[:, b, torch.unique(src2trg[src[:,b]])] = 1\n        outputs = outputs* mask\n        return(outputs)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-27T03:44:26.910142Z","iopub.execute_input":"2022-04-27T03:44:26.910854Z","iopub.status.idle":"2022-04-27T03:44:26.918523Z","shell.execute_reply.started":"2022-04-27T03:44:26.910812Z","shell.execute_reply":"2022-04-27T03:44:26.917628Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"INPUT_DIM = len(vocab_transform[SRC_LANGUAGE])\nOUTPUT_DIM = len(vocab_transform[TGT_LANGUAGE])\n\nEMB_SIZE = 100\nHID_SIZE = 50\n\nsrc_embed = nn.Embedding(len(vocab_transform[SRC_LANGUAGE]), EMB_SIZE, padding_idx=PAD_IDX)\nif pretrained_embed:\n  \n  src_embed.load_state_dict({'weight': torch.cat([src_embed.weight[:4].data, ft_embed.vectors])})\n  ft_embed = None\n  src_embed.requires_grad_(False)\n\n\nmodel = Model(INPUT_DIM, OUTPUT_DIM, EMB_SIZE, HID_SIZE, 2,  PAD_IDX, EOS_IDX, device, src_embed=None, trg_embed=None).to(device)","metadata":{"id":"snch6VGQ9enh","execution":{"iopub.status.busy":"2022-04-27T03:44:27.956758Z","iopub.execute_input":"2022-04-27T03:44:27.957320Z","iopub.status.idle":"2022-04-27T03:44:28.345340Z","shell.execute_reply.started":"2022-04-27T03:44:27.957278Z","shell.execute_reply":"2022-04-27T03:44:28.344587Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"if not pretrained_embed:\n  def init_weights(m): \n    for name, param in m.named_parameters(): \n      if 'weight' in name: \n        nn.init.normal_(param.data, mean=0, std=0.01) \n      else: nn.init.constant_(param.data, 0)\n\n  model.apply(init_weights)","metadata":{"id":"0iBo0rqCS5Y3","execution":{"iopub.status.busy":"2022-04-27T03:44:29.012708Z","iopub.execute_input":"2022-04-27T03:44:29.013345Z","iopub.status.idle":"2022-04-27T03:44:29.023196Z","shell.execute_reply.started":"2022-04-27T03:44:29.013286Z","shell.execute_reply":"2022-04-27T03:44:29.022136Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'Модель содержит {count_parameters(model):,} параметров')","metadata":{"id":"0cp0OEmN9eni","outputId":"76e623ab-5827-4644-de89-de4c7846c0a2","execution":{"iopub.status.busy":"2022-04-27T03:44:29.757711Z","iopub.execute_input":"2022-04-27T03:44:29.758300Z","iopub.status.idle":"2022-04-27T03:44:29.765062Z","shell.execute_reply.started":"2022-04-27T03:44:29.758257Z","shell.execute_reply":"2022-04-27T03:44:29.764051Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Модель содержит 37,404,584 параметров\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr =2e-3)\ncriterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\nsched = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n","metadata":{"id":"JFfoCLut9enj","execution":{"iopub.status.busy":"2022-04-27T03:44:30.388754Z","iopub.execute_input":"2022-04-27T03:44:30.389492Z","iopub.status.idle":"2022-04-27T03:44:30.395421Z","shell.execute_reply.started":"2022-04-27T03:44:30.389440Z","shell.execute_reply":"2022-04-27T03:44:30.394365Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = 12\nCLIP = float('inf')\nbest_valid_loss = float('inf')\nmodel.forward_mode = 'next_word'\n\nfor epoch in tqdm(range(N_EPOCHS)):\n\n\n    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, device)\n    valid_loss = evaluate(model, valid_iterator, criterion, device)\n    \n    \n    sched.step(valid_loss)\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'translate_model.pt')\n    \n    print(f'Перплексия (обучение): {math.exp(train_loss):7.3f}')\n    print(f'Перплексия (валидация): {math.exp(valid_loss):7.3f}')","metadata":{"id":"0qCCmsOB9enk","outputId":"7578c5da-5a0e-493c-e071-e810396d2612","scrolled":true,"execution":{"iopub.status.busy":"2022-04-27T04:05:49.563048Z","iopub.execute_input":"2022-04-27T04:05:49.563318Z","iopub.status.idle":"2022-04-27T04:31:44.493630Z","shell.execute_reply.started":"2022-04-27T04:05:49.563286Z","shell.execute_reply":"2022-04-27T04:31:44.492301Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"  2%|▏         | 1/50 [10:39<8:42:16, 639.52s/it]","output_type":"stream"},{"name":"stdout","text":"Перплексия (обучение):  84.256\nПерплексия (валидация): 691.736\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 2/50 [21:17<8:30:41, 638.37s/it]","output_type":"stream"},{"name":"stdout","text":"Перплексия (обучение):  61.274\nПерплексия (валидация): 618.827\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 2/50 [25:54<10:21:57, 777.44s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34/1430077803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/stepik_nnets/sec2sec/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#trg = [trg sent len, batch size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_34/877959626.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, teacher_forcing_ratio, *args)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/stepik_nnets/sec2sec/models/only_gru.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, teacher_forcing_ratio, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \"\"\"\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# src len x batch_size x hidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'greedy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/stepik_nnets/sec2sec/models/only_gru.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0msrc_embeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_embeded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;31m# src len x batch_size x hidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 838\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    839\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load('translate_model.pt', map_location=device))","metadata":{"id":"TofKSsiMHT-O","outputId":"2a36abe4-50af-416b-83c6-81fda569ffe3","execution":{"iopub.status.busy":"2022-04-24T17:55:19.371087Z","iopub.execute_input":"2022-04-24T17:55:19.371728Z","iopub.status.idle":"2022-04-24T17:55:19.451014Z","shell.execute_reply.started":"2022-04-24T17:55:19.371693Z","shell.execute_reply":"2022-04-24T17:55:19.450324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = 5\nCLIP = float('inf')\nbest_valid_loss = float('inf')\nmodel.forward_mode = 'greedy'\n\nfor epoch in tqdm(range(N_EPOCHS)):\n\n\n    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, device)\n    valid_loss = evaluate(model, valid_iterator, criterion, device)\n    \n    \n    sched.step(valid_loss)\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'translate_model.pt')\n    \n    print(f'Перплексия (обучение): {math.exp(train_loss):7.3f}')\n    print(f'Перплексия (валидация): {math.exp(valid_loss):7.3f}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('translate_model.pt', map_location=device))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Titiling","metadata":{"id":"RBqZI3iA9enl"}},{"cell_type":"code","source":"\n    \ndef data_to_device (data, device):\n    if isinstance(data, Sequence):\n        data = (d.to(device) for d in data)\n    else:\n        data = data.to(device)\n    return data\n\ndef predict_with_model(model, iterator, vocab: Vocab,  device = None):\n    model.eval()\n    device = model.device\n    condidate_corpus = []\n    ref_corpus = []\n\n    for batch in iterator:\n      with torch.no_grad():\n          src, trg = data_to_device(batch, device)\n          #pred_trg, scores = beam_search_rnn(model,src, beam_size=3, max_len=20, device=device)\n          #pred_trg = pred_trg[:,:,0]\n\n          pred_trg = model(src, trg, 0)\n          pred_trg = pred_trg.argmax(-1)\n          \n          for i in range(src.shape[1]):\n              candidat = pred_trg[:,i][(pred_trg[:,i] != model.eos_idx) & (pred_trg[:,i] != model.pad_idx) ]\n              candidat = vocab.lookup_tokens(list(candidat.cpu().numpy()))\n\n              ref = trg[:,i][(trg[:,i] != model.eos_idx) & (trg[:,i] != model.pad_idx) & (trg[:,i] != 2) ]\n              ref = vocab.lookup_tokens(list(ref.cpu().numpy()))\n\n              condidate_corpus.append(candidat)\n              ref_corpus.append([ref])\n    return condidate_corpus, ref_corpus\n","metadata":{"id":"MvFTlmmsXQ2M","execution":{"iopub.status.busy":"2022-04-27T04:33:41.152134Z","iopub.execute_input":"2022-04-27T04:33:41.152482Z","iopub.status.idle":"2022-04-27T04:33:41.163995Z","shell.execute_reply.started":"2022-04-27T04:33:41.152435Z","shell.execute_reply":"2022-04-27T04:33:41.163145Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model.forward_mode = 'greedy'\ncondidat_corpus, ref_corpus = predict_with_model(model, valid_iterator, vocab_transform['title'])","metadata":{"id":"OLEooAeIcsr6","execution":{"iopub.status.busy":"2022-04-27T04:33:49.165734Z","iopub.execute_input":"2022-04-27T04:33:49.166004Z","iopub.status.idle":"2022-04-27T04:37:32.180233Z","shell.execute_reply.started":"2022-04-27T04:33:49.165970Z","shell.execute_reply":"2022-04-27T04:37:32.179392Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"bleu_score(condidat_corpus, ref_corpus, max_n=3, weights=[0.34, 0.33, 0.33])","metadata":{"id":"uV2cvKHXfSbh","outputId":"d296a5ce-fcde-411f-baff-b85153e30e00","execution":{"iopub.status.busy":"2022-04-27T04:37:32.181970Z","iopub.execute_input":"2022-04-27T04:37:32.183847Z","iopub.status.idle":"2022-04-27T04:37:32.229886Z","shell.execute_reply.started":"2022-04-27T04:37:32.183800Z","shell.execute_reply":"2022-04-27T04:37:32.228538Z"},"trusted":true},"execution_count":44,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34/3156094185.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondidat_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.33\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchtext/data/metrics.py\u001b[0m in \u001b[0;36mbleu_score\u001b[0;34m(candidate_corpus, references_corpus, max_n, weights)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate_counter\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: no need to loop through the whole counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mtotal_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcandidate_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 0 with size 3"],"ename":"IndexError","evalue":"index 3 is out of bounds for dimension 0 with size 3","output_type":"error"}]},{"cell_type":"code","source":"for i in range(10):\n    print(' '. join(ref_corpus[i][0]))\n    print(' '.join(condidat_corpus[i]))\n    print('')\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-26T18:59:12.772288Z","iopub.execute_input":"2022-04-26T18:59:12.772618Z","iopub.status.idle":"2022-04-26T18:59:12.790656Z","shell.execute_reply.started":"2022-04-26T18:59:12.772572Z","shell.execute_reply":"2022-04-26T18:59:12.790001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_data = pd.read_csv('/kaggle/input/title-generation/test.csv')\nabstracts = submission_data['abstract'].values\ntest_iter = [(a, 'a '*20) for a in abstracts]\ntest_dataset = Sec2SecDataset( test_iter, text_transform, PAD_IDX, ln_pair = ln_pair)\ntest_iterator = DataLoader(test_dataset, batch_size=30, collate_fn = test_dataset.pad_collate_fn)\n\ntest_preds, _ = predict_with_model(model, test_iterator, vocab_transform['title'])","metadata":{"execution":{"iopub.status.busy":"2022-04-27T04:01:37.234930Z","iopub.execute_input":"2022-04-27T04:01:37.235703Z","iopub.status.idle":"2022-04-27T04:01:39.424502Z","shell.execute_reply.started":"2022-04-27T04:01:37.235642Z","shell.execute_reply":"2022-04-27T04:01:39.423708Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"\ntitles = []\nfor t_pred in test_preds:\n\n    #title, _ = translate_sentence(model, abstract.split())\n    titles.append(' '.join(t_pred).replace('<unk>', ''))\n    \nsubmission_df = pd.DataFrame({'abstract': abstracts, 'title': titles})\nsubmission_df.to_csv('predicted_titles.csv', index=False)","metadata":{"id":"LYNVOFDbcKg3","execution":{"iopub.status.busy":"2022-04-27T04:01:40.870510Z","iopub.execute_input":"2022-04-27T04:01:40.870776Z","iopub.status.idle":"2022-04-27T04:01:40.921096Z","shell.execute_reply.started":"2022-04-27T04:01:40.870745Z","shell.execute_reply":"2022-04-27T04:01:40.920392Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import string\nfrom nltk.util import ngrams\nimport numpy as np\nimport pandas as pd\nimport pickle\n\n\ndef generate_csv(input_file='predicted_titles.csv',\n                 output_file='submission.csv',\n                 voc_file='/kaggle/input/title-generation/vocs.pkl'):\n    '''\n    Generates file in format required for submitting result to Kaggle\n    \n    Parameters:\n        input_file (str) : path to csv file with your predicted titles.\n                           Should have two fields: abstract and title\n        output_file (str) : path to output submission file\n        voc_file (str) : path to voc.pkl file\n    '''\n    data = pd.read_csv(input_file)\n    with open(voc_file, 'rb') as voc_file:\n        vocs = pickle.load(voc_file)\n\n    with open(output_file, 'w') as res_file:\n        res_file.write('Id,Predict\\n')\n        \n    output_idx = 0\n    for row_idx, row in data.iterrows():\n        try:\n            trg = row['title']\n            trg = trg.translate(str.maketrans('', '', string.punctuation)).lower().split()\n            trg.extend(['_'.join(ngram) for ngram in list(ngrams(trg, 2)) + list(ngrams(trg, 3))])\n\n            VOCAB_stoi = vocs[row_idx]\n            trg_intersection = set(VOCAB_stoi.keys()).intersection(set(trg))\n            trg_vec = np.zeros(len(VOCAB_stoi))    \n\n            for word in trg_intersection:\n                trg_vec[VOCAB_stoi[word]] = 1\n\n            with open(output_file, 'a') as res_file:\n                for is_word in trg_vec:\n                    res_file.write('{0},{1}\\n'.format(output_idx, int(is_word)))\n                    output_idx += 1\n        except:\n            continue\n\n\ngenerate_csv()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T04:04:59.790828Z","iopub.execute_input":"2022-04-27T04:04:59.791103Z","iopub.status.idle":"2022-04-27T04:05:00.416377Z","shell.execute_reply.started":"2022-04-27T04:04:59.791073Z","shell.execute_reply":"2022-04-27T04:05:00.415614Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
