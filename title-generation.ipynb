{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/ArtemNechaev/stepik_nnets \n!pip install youtokentome","metadata":{"id":"HmgOOdMD3AmR","outputId":"e39c6e16-6ec9-4457-b34b-a516c2f5197b","execution":{"iopub.status.busy":"2022-05-03T14:45:58.278983Z","iopub.execute_input":"2022-05-03T14:45:58.279349Z","iopub.status.idle":"2022-05-03T14:46:11.416481Z","shell.execute_reply.started":"2022-05-03T14:45:58.279271Z","shell.execute_reply":"2022-05-03T14:46:11.415575Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'stepik_nnets'...\nremote: Enumerating objects: 159, done.\u001b[K\nremote: Counting objects: 100% (159/159), done.\u001b[K\nremote: Compressing objects: 100% (128/128), done.\u001b[K\nremote: Total 159 (delta 76), reused 64 (delta 24), pack-reused 0\u001b[K\nReceiving objects: 100% (159/159), 2.38 MiB | 3.38 MiB/s, done.\nResolving deltas: 100% (76/76), done.\nCollecting youtokentome\n  Downloading youtokentome-1.0.6-cp37-cp37m-manylinux2010_x86_64.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n\u001b[?25hRequirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.7/site-packages (from youtokentome) (8.0.4)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click>=7.0->youtokentome) (4.11.3)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=7.0->youtokentome) (3.7.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=7.0->youtokentome) (4.1.1)\nInstalling collected packages: youtokentome\nSuccessfully installed youtokentome-1.0.6\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\n\nfrom collections import OrderedDict, Counter\n\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator, FastText, vocab\nfrom torchtext.data.metrics import bleu_score\nfrom torchtext.datasets import Multi30k\nfrom typing import Iterable, List\n\nfrom stepik_nnets.sec2sec.data import Sec2SecDataset, sequential_transforms, TensorTransform, myFastText\nfrom stepik_nnets.sec2sec.models import OnlyGRU, Seq2SeqTransformer\n\nfrom stepik_nnets.sec2sec.engine import train, evaluate, predict_with_model, data_to_device\nfrom stepik_nnets.sec2sec.beam_search import  beam_search_transformer\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\n\nimport youtokentome as yttm\n\nimport random\nimport math\nimport time\nfrom tqdm import tqdm\nimport pickle\n\nimport zipfile\n","metadata":{"id":"6dneov4I9enW","outputId":"ac4780f6-70dd-435c-c474-0855d114cbad","execution":{"iopub.status.busy":"2022-05-03T14:46:15.930408Z","iopub.execute_input":"2022-05-03T14:46:15.930665Z","iopub.status.idle":"2022-05-03T14:46:15.939334Z","shell.execute_reply.started":"2022-05-03T14:46:15.930636Z","shell.execute_reply":"2022-05-03T14:46:15.938659Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from typing import Sequence\nimport torch\n\ndef beam_search(dec_out, indeces, scores, beam_size, pad_idx, eos_idx):\n    batch_size = int(dec_out.shape[1]/beam_size)\n    \n    # 1 x batch_size*beam_size x vocab_size\n    new_score = dec_out.log_softmax(-1) \n\n    # 1 x batch_size*beam_size x beam_size\n    new_score, new_idx = new_score.topk(beam_size)\n\n    new_score[:, torch.where(indeces[-1].flatten() == eos_idx)[0]] = 0\n    scores = scores.reshape(1, batch_size*beam_size, 1) + new_score\n\n    lens_hyp = ((indeces != eos_idx) & (indeces != pad_idx)).sum(0, keepdim=True).reshape(1, batch_size*beam_size, 1)\n    scores = scores/(lens_hyp+1)**0.5\n\n    ######scores, new_idx = scores.topk(beam_size) #1 x  batch_size*beam_size x beam_size\n    flatten_scores = scores.reshape(1,batch_size, beam_size ** 2)\n\n    # 1 x batch_size x beam_size. order_scores [0 .. beam_size**2 - 1]\n    scores, order_scores = flatten_scores.topk(beam_size) \n\n    \n    # calc beam indexes that got top beam_size scores. beam_ids [0 .. beam_size - 1]\n    beam_ids = torch.div(order_scores, beam_size, rounding_mode='floor') \n\n    #select beams with top scores from indeces and concat new idx.\n    #start of sentences could repeat.\n\n    indeces = torch.cat([\n                         torch.gather(indeces, -1, beam_ids.repeat(indeces.shape[0], 1, 1)),\n                         torch.gather(new_idx.view(1, batch_size, -1),-1,order_scores)\n    ])\n    \n    return indeces, scores, beam_ids\n\ndef beam_search_rnn( model, src, beam_size=5, max_len=20):\n  \"\"\"\n  src - src_len x batch_size\n  return tensor max_len x batch_size x beam_size\n  \"\"\"\n  model.eval()\n  device = model.device\n\n  src = src.to(model.device)\n  batch_size = src.shape[1]\n\n  # src_len x batch_size x hidden_size\n  encoder_outputs, h_0 = model.encode(src) \n\n  # 1 x batch_size\n  input_trg = src[0].unsqueeze(0) \n  mask = model.create_pad_mask(src, input_trg)\n\n  # 1 x batch_size x vocab_size\n  first_decode, att, h_0 = model.decode(encoder_outputs, input_trg, mask, h_0=h_0 ) \n  first_decode = first_decode.log_softmax(-1)\n\n  # 1 x batch_size x beam_size\n  scores, indeces = first_decode.topk(beam_size) \n\n  # decoder hidden_state. num_layers * D, batch_size*beam_size, hidden\n  h_0 = h_0.unsqueeze(2).repeat(1,1,beam_size,1).reshape(h_0.shape[0], batch_size*beam_size, -1) \n\n  # src_len x batch_size*beam_size x hidden_size\n  encoder_outputs = encoder_outputs.unsqueeze(2).repeat(1,1,beam_size,1).reshape(src.shape[0], batch_size*beam_size, -1)\n\n  # src_len x batch_size*beam_size\n  src = src.unsqueeze(2).repeat(1,1,beam_size).reshape(src.shape[0], batch_size*beam_size)\n\n  for i in range(1, max_len):\n    input_trg = indeces[-1].view(1, batch_size * beam_size )\n    mask = model.create_pad_mask(src, input_trg)\n    dec_out , att, h_0 = model.decode(encoder_outputs, input_trg, mask, h_0=h_0)\n    \n    indeces, scores, beam_ids = beam_search(dec_out, indeces, scores, beam_size, model.pad_idx, model.eos_idx)\n\n    #select beams with top scores from decoder hidden_state\n    h_0 = h_0.reshape(h_0.shape[0], batch_size, beam_size, -1)\n    h_0 = torch.gather(h_0, 2, beam_ids.unsqueeze(3).repeat(h_0.shape[0], 1, 1, h_0.shape[3]))\n    h_0 = h_0.reshape(h_0.shape[0], batch_size*beam_size, -1)\n\n\n  return indeces, scores\n\n\ndef beam_search_transformer( model, src, beam_size=5, max_len=20):\n  \"\"\"\n  src - src_len x batch_size\n  return tensor max_len x batch_size x beam_size\n  \"\"\"\n  model.eval()\n  device = model.device\n\n  src = src.to(model.device)\n  input_trg = src[0].unsqueeze(0) \n  batch_size = src.shape[1]\n  \n  src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = model.create_mask(src, input_trg)\n    \n  # src_len x batch_size x hidden_size\n  encoder_outputs = model.encode(src, src_mask, src_padding_mask) \n\n  # 1 x batch_size x vocab_size\n  first_decode = model.decode(input_trg, encoder_outputs,  tgt_mask) \n  first_decode = first_decode.log_softmax(-1)\n\n  # 1 x batch_size x beam_size\n  scores, indeces = first_decode.topk(beam_size) \n\n  # src_len x batch_size*beam_size x hidden_size\n  encoder_outputs = encoder_outputs.unsqueeze(2).repeat(1,1,beam_size,1).reshape(src.shape[0], batch_size*beam_size, -1)\n\n  # src_len x batch_size*beam_size\n  src = src.unsqueeze(2).repeat(1,1,beam_size).reshape(src.shape[0], batch_size*beam_size)\n\n  for i in range(1, max_len):\n    input_trg = indeces.view(indeces.shape[0], batch_size * beam_size )\n    \n    tgt_mask = (model.generate_square_subsequent_mask(indeces.shape[0])\n                    .type(torch.bool)).to(device)\n    dec_out = model.decode( input_trg, encoder_outputs, tgt_mask)\n\n    indeces, scores, beam_ids = beam_search(dec_out[-1].unsqueeze(0), indeces, scores, beam_size, model.pad_idx, model.eos_idx)\n\n  return indeces, scores","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:55:50.027884Z","iopub.execute_input":"2022-05-03T14:55:50.028238Z","iopub.status.idle":"2022-05-03T14:55:50.053419Z","shell.execute_reply.started":"2022-05-03T14:55:50.028205Z","shell.execute_reply":"2022-05-03T14:55:50.052515Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from torch import Tensor\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Transformer\nimport math\n\n\n# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\nclass PositionalEncoding(nn.Module):\n    def __init__(self,\n                 emb_size: int,\n                 dropout: float,\n                 maxlen: int = 5000):\n        super(PositionalEncoding, self).__init__()\n        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n        pos_embedding = torch.zeros((maxlen, emb_size))\n        pos_embedding[:, 0::2] = torch.sin(pos * den)\n        pos_embedding[:, 1::2] = torch.cos(pos * den)\n        pos_embedding = pos_embedding.unsqueeze(-2)\n\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer('pos_embedding', pos_embedding)\n\n    def forward(self, token_embedding: Tensor):\n        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n\n# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\nclass TokenEmbedding(nn.Module):\n    def __init__(self, vocab_size: int, emb_size):\n        super(TokenEmbedding, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, emb_size)\n        self.emb_size = emb_size\n\n    def forward(self, tokens: Tensor):\n        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n\n# Seq2Seq Network\nclass Seq2SeqTransformer(nn.Module):\n    def __init__(self,\n                 num_encoder_layers: int,\n                 num_decoder_layers: int,\n                 emb_size: int,\n                 nhead: int,\n                 src_vocab_size: int,\n                 tgt_vocab_size: int,\n                 pad_idx: int,\n                 eos_idx: int,\n                 device,\n                 dim_feedforward: int = 512,\n                 dropout: float = 0.1):\n        super(Seq2SeqTransformer, self).__init__()\n        self.device = device\n        self.pad_idx = pad_idx\n        self.eos_idx = eos_idx\n        self.transformer = Transformer(d_model=emb_size,\n                                       nhead=nhead,\n                                       num_encoder_layers=num_encoder_layers,\n                                       num_decoder_layers=num_decoder_layers,\n                                       dim_feedforward=dim_feedforward,\n                                       dropout=dropout)\n        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n        self.positional_encoding = PositionalEncoding(\n            emb_size, dropout=dropout)\n\n    def forward(self,\n                src: Tensor,\n                trg: Tensor,\n\n                *args):\n        src_emb = self.positional_encoding(self.src_tok_emb(src))\n        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = self.create_mask(src, trg)\n        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n                                src_padding_mask, tgt_padding_mask, src_padding_mask)\n        return self.generator(outs)\n\n    def encode(self, src: Tensor, src_mask: Tensor, src_padding_mask: Tensor = None):\n        return self.transformer.encoder(self.positional_encoding(\n                            self.src_tok_emb(src)), src_mask, src_padding_mask)\n\n    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor, tgt_padding_mask: Tensor = None):\n        outs =  self.transformer.decoder(self.positional_encoding(\n                          self.tgt_tok_emb(tgt)), memory,\n                          tgt_mask, tgt_padding_mask)\n        return self.generator(outs)\n\n    def generate_square_subsequent_mask(self, sz):\n        mask = (torch.triu(torch.ones((sz, sz), device=self.device)) == 1).transpose(0, 1)\n        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n        return mask\n\n\n    def create_mask(self, src, tgt):\n        src_seq_len = src.shape[0]\n        tgt_seq_len = tgt.shape[0]\n\n        tgt_mask = self. generate_square_subsequent_mask(tgt_seq_len)\n        src_mask = torch.zeros((src_seq_len, src_seq_len),device=self.device).type(torch.bool)\n\n        src_padding_mask = (src == self.pad_idx).transpose(0, 1)\n        tgt_padding_mask = (tgt == self.pad_idx).transpose(0, 1)\n        return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:53:32.696817Z","iopub.execute_input":"2022-05-03T14:53:32.697099Z","iopub.status.idle":"2022-05-03T14:53:32.720346Z","shell.execute_reply.started":"2022-05-03T14:53:32.697069Z","shell.execute_reply":"2022-05-03T14:53:32.719637Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"SEED = 0\n\n\nrandom.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n\ninput = '/kaggle/input/title-generation'\noutput ='/kaggle/working'\n\ntrain_data_path = \"/train_data.txt\"\nmodel_path = \"/yttm.model\"\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"id":"LonnFFNd9enX","execution":{"iopub.status.busy":"2022-05-03T14:46:23.080478Z","iopub.execute_input":"2022-05-03T14:46:23.080732Z","iopub.status.idle":"2022-05-03T14:46:23.093137Z","shell.execute_reply.started":"2022-05-03T14:46:23.080705Z","shell.execute_reply":"2022-05-03T14:46:23.092193Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv(f'{input}/train.csv')\ndf.to_csv(f'{output}{train_data_path}', header=None, index=None, sep=' ', mode='a')\n_, all = zip(*df.iterrows())\nall = list(all)\nTRAIN_SPLIT = int(len(all) * 0.9)\nnp.random.shuffle(all)\ntrain_iter = all[:TRAIN_SPLIT]\nval_iter = all[TRAIN_SPLIT:]\nall = None\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:46:28.229708Z","iopub.execute_input":"2022-05-03T14:46:28.229966Z","iopub.status.idle":"2022-05-03T14:46:44.109055Z","shell.execute_reply.started":"2022-05-03T14:46:28.229937Z","shell.execute_reply":"2022-05-03T14:46:44.108293Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Training model\nyttm.BPE.train(data=f'{output}{train_data_path}', vocab_size=20000, model=f'{output}{model_path}')\n\n# Loading model\nbpe = yttm.BPE(model=f'{output}{model_path}')","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:46:47.009872Z","iopub.execute_input":"2022-05-03T14:46:47.010394Z","iopub.status.idle":"2022-05-03T14:46:55.741794Z","shell.execute_reply.started":"2022-05-03T14:46:47.010353Z","shell.execute_reply":"2022-05-03T14:46:55.740974Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Training parameters\n  input: /kaggle/working/train_data.txt\n  model: /kaggle/working/yttm.model\n  vocab_size: 20000\n  n_threads: 2\n  character_coverage: 1\n  pad: 0\n  unk: 1\n  bos: 2\n  eos: 3\n\nreading file...\nlearning bpe...\nnumber of unique characters in the training data: 69\nnumber of deleted characters: 0\nnumber of unique characters left: 69\nid: 1000=5+182                freq: 12976       subword: eff=e+ff\nid: 2000=1101+94              freq: 5056        subword: ▁basis=▁bas+is\nid: 3000=8+20                 freq: 2749        subword: af=a+f\nid: 4000=10+6                 freq: 1743        subword: nt=n+t\nid: 5000=85+455               freq: 1234        subword: enced=en+ced\nid: 6000=219+3792             freq: 925         subword: ▁seems=▁se+ems\nid: 7000=681+110              freq: 705         subword: ▁valuation=▁valu+ation\nid: 8000=1293+27              freq: 562         subword: ▁task,=▁task+,\nid: 9000=88+22                freq: 459         subword: ▁pb=▁p+b\nid: 10000=329+9008            freq: 384         subword: ▁contempor=▁cont+empor\nid: 11000=14+160              freq: 327         subword: city=c+ity\nid: 12000=2879+482            freq: 284         subword: ▁accelerating=▁acceler+ating\nid: 13000=781+221             freq: 247         subword: ▁framework.\"=▁framework+.\"\nid: 14000=2154+252            freq: 218         subword: ▁cosine=▁cos+ine\nid: 15000=138+3060            freq: 193         subword: ▁\"vis=▁\"+vis\nid: 16000=10586+133           freq: 172         subword: ▁scarce=▁scar+ce\nid: 17000=97+1681             freq: 155         subword: ▁injective=▁in+jective\nid: 18000=10045+11            freq: 140         subword: ▁subsystems=▁subsystem+s\nid: 19000=3028+234            freq: 127         subword: ▁allocated=▁alloc+ated\nmodel saved to: /kaggle/working/yttm.model\n","output_type":"stream"}]},{"cell_type":"code","source":"from typing import List\n\nSRC_LANGUAGE = 'abs'\nTGT_LANGUAGE = 'title'\n\nln_pair = (SRC_LANGUAGE, TGT_LANGUAGE)\n\n# Define special symbols and indices\nUNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n# Make sure the tokens are in order of their indices to properly insert them in vocab\nspecial_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n\ntransform = sequential_transforms(\n    bpe.encode,\n    TensorTransform(BOS_IDX, EOS_IDX)\n)\n\ntext_transform = {}\nfor ln in ln_pair:\n    text_transform[ln] = transform\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:47:37.900098Z","iopub.execute_input":"2022-05-03T14:47:37.901013Z","iopub.status.idle":"2022-05-03T14:47:37.907007Z","shell.execute_reply.started":"2022-05-03T14:47:37.900950Z","shell.execute_reply":"2022-05-03T14:47:37.906026Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_dataset = Sec2SecDataset( train_iter, text_transform, PAD_IDX, ln_pair = ln_pair)\ntrain_iterator = DataLoader(train_dataset, batch_size=64, shuffle = True, collate_fn = train_dataset.pad_collate_fn)\n\nval_dataset = Sec2SecDataset( val_iter, text_transform, PAD_IDX, ln_pair = ln_pair)\nvalid_iterator = DataLoader(val_dataset, batch_size=64, collate_fn = train_dataset.pad_collate_fn)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:47:41.289703Z","iopub.execute_input":"2022-05-03T14:47:41.290274Z","iopub.status.idle":"2022-05-03T14:48:13.699291Z","shell.execute_reply.started":"2022-05-03T14:47:41.290236Z","shell.execute_reply":"2022-05-03T14:48:13.698505Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Процент встречаемости слов из заголовка в исходном тексте\nres = [sum(1 for t in title if t in a) /len(title) for a, title in  train_dataset]\nsum(res)/len(res)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T14:48:13.701099Z","iopub.execute_input":"2022-05-03T14:48:13.701364Z","iopub.status.idle":"2022-05-03T14:48:27.641524Z","shell.execute_reply.started":"2022-05-03T14:48:13.701328Z","shell.execute_reply":"2022-05-03T14:48:27.640853Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0.7902344797268247"},"metadata":{}}]},{"cell_type":"code","source":"INPUT_DIM = bpe.vocab_size()\nOUTPUT_DIM = INPUT_DIM\n\nEMB_SIZE =300\nN_HEAD = 2\n\nmodel = Seq2SeqTransformer(\n                 2,\n                 2,\n                 EMB_SIZE,\n                 N_HEAD,\n                 INPUT_DIM,\n                 OUTPUT_DIM,\n                 PAD_IDX,\n                 EOS_IDX,\n                 device,\n                 dim_feedforward = 512,\n                 dropout= 0.1).to(device)\n\nfor p in model.parameters():\n    if p.dim() > 1:\n        nn.init.xavier_uniform_(p)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T15:10:08.082267Z","iopub.execute_input":"2022-05-03T15:10:08.082779Z","iopub.status.idle":"2022-05-03T15:10:08.297500Z","shell.execute_reply.started":"2022-05-03T15:10:08.082738Z","shell.execute_reply":"2022-05-03T15:10:08.296764Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'Модель содержит {count_parameters(model):,} параметров')","metadata":{"id":"0cp0OEmN9eni","outputId":"76e623ab-5827-4644-de89-de4c7846c0a2","execution":{"iopub.status.busy":"2022-05-03T15:10:09.459798Z","iopub.execute_input":"2022-05-03T15:10:09.460395Z","iopub.status.idle":"2022-05-03T15:10:09.468910Z","shell.execute_reply.started":"2022-05-03T15:10:09.460356Z","shell.execute_reply":"2022-05-03T15:10:09.467768Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Модель содержит 21,426,448 параметров\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n\ncriterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\nsched = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n","metadata":{"id":"JFfoCLut9enj","execution":{"iopub.status.busy":"2022-05-03T15:10:16.571213Z","iopub.execute_input":"2022-05-03T15:10:16.571601Z","iopub.status.idle":"2022-05-03T15:10:16.578347Z","shell.execute_reply.started":"2022-05-03T15:10:16.571567Z","shell.execute_reply":"2022-05-03T15:10:16.576799Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = 12\nCLIP = float('inf')\nbest_valid_loss = float('inf')\nmodel.forward_mode = 'next_word'\n\nfor epoch in tqdm(range(N_EPOCHS)):\n\n\n    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, device)\n    valid_loss = evaluate(model, valid_iterator, criterion, device)\n    \n    \n    sched.step(valid_loss)\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'translate_model.pt')\n    \n    print(f'Перплексия (обучение): {math.exp(train_loss):7.3f}')\n    print(f'Перплексия (валидация): {math.exp(valid_loss):7.3f}')","metadata":{"id":"0qCCmsOB9enk","outputId":"7578c5da-5a0e-493c-e071-e810396d2612","scrolled":true,"execution":{"iopub.status.busy":"2022-05-03T15:10:29.310099Z","iopub.execute_input":"2022-05-03T15:10:29.310689Z","iopub.status.idle":"2022-05-03T16:03:47.747271Z","shell.execute_reply.started":"2022-05-03T15:10:29.310652Z","shell.execute_reply":"2022-05-03T16:03:47.746566Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"  8%|▊         | 1/12 [04:26<48:47, 266.09s/it]","output_type":"stream"},{"name":"stdout","text":"Перплексия (обучение): 778.618\nПерплексия (валидация): 395.535\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 2/12 [08:52<44:19, 266.00s/it]","output_type":"stream"},{"name":"stdout","text":"Перплексия (обучение): 319.875\nПерплексия (валидация): 236.348\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 3/12 [13:18<39:57, 266.36s/it]","output_type":"stream"},{"name":"stdout","text":"Перплексия (обучение): 201.577\nПерплексия (валидация): 162.606\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 4/12 [17:45<35:31, 266.45s/it]","output_type":"stream"},{"name":"stdout","text":"Перплексия (обучение): 137.516\nПерплексия (валидация): 119.283\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 5/12 [22:11<31:04, 266.38s/it]","output_type":"stream"},{"name":"stdout","text":"Перплексия (обучение):  98.658\nПерплексия (валидация):  94.817\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 6/12 [26:38<26:38, 266.47s/it]","output_type":"stream"},{"name":"stdout","text":"Перплексия (обучение):  74.139\nПерплексия (валидация):  78.969\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 7/12 [31:04<22:12, 266.53s/it]","output_type":"stream"},{"name":"stdout","text":"Перплексия (обучение):  57.869\nПерплексия (валидация):  68.135\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 8/12 [35:31<17:46, 266.57s/it]","output_type":"stream"},{"name":"stdout","text":"Перплексия (обучение):  46.413\nПерплексия (валидация):  60.671\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 9/12 [39:58<13:20, 266.74s/it]","output_type":"stream"},{"name":"stdout","text":"Перплексия (обучение):  38.056\nПерплексия (валидация):  54.624\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 10/12 [44:25<08:53, 266.82s/it]","output_type":"stream"},{"name":"stdout","text":"Перплексия (обучение):  31.793\nПерплексия (валидация):  50.719\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 11/12 [48:52<04:26, 266.75s/it]","output_type":"stream"},{"name":"stdout","text":"Перплексия (обучение):  26.976\nПерплексия (валидация):  47.028\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [53:18<00:00, 266.54s/it]","output_type":"stream"},{"name":"stdout","text":"Перплексия (обучение):  23.210\nПерплексия (валидация):  44.371\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load('translate_model.pt', map_location=device))","metadata":{"id":"TofKSsiMHT-O","outputId":"2a36abe4-50af-416b-83c6-81fda569ffe3","execution":{"iopub.status.busy":"2022-05-03T16:04:02.486937Z","iopub.execute_input":"2022-05-03T16:04:02.487628Z","iopub.status.idle":"2022-05-03T16:04:02.546422Z","shell.execute_reply.started":"2022-05-03T16:04:02.487592Z","shell.execute_reply":"2022-05-03T16:04:02.545575Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Titiling","metadata":{"id":"RBqZI3iA9enl"}},{"cell_type":"code","source":"\ndef predict_with_model(model, iterator, vocab,  device = None):\n    model.eval()\n    device = model.device\n    condidate_corpus = []\n    ref_corpus = []\n\n    for batch in iterator:\n      with torch.no_grad():\n          src, trg = data_to_device(batch, device)\n          pred_trg, scores = beam_search_transformer(model,src, beam_size=5, max_len=20)\n          pred_trg = pred_trg[:,:,0]\n\n          #pred_trg = model(src, trg, 0)\n          #pred_trg = pred_trg.argmax(-1)\n          \n          for i in range(src.shape[1]):\n              candidat = pred_trg[:,i][(pred_trg[:,i] != model.eos_idx) & (pred_trg[:,i] != model.pad_idx) ]\n              candidat = vocab.decode([list(candidat.cpu().numpy())])[0].split()\n\n              ref = trg[1:,i][(trg[1:,i] != model.eos_idx) & (trg[1:,i] != model.pad_idx) ]\n              ref = vocab.decode([list(ref.cpu().numpy())])[0].split()\n\n              condidate_corpus.append(candidat)\n              ref_corpus.append([ref])\n    return condidate_corpus, ref_corpus\n","metadata":{"id":"MvFTlmmsXQ2M","execution":{"iopub.status.busy":"2022-05-03T16:05:53.377789Z","iopub.execute_input":"2022-05-03T16:05:53.378070Z","iopub.status.idle":"2022-05-03T16:05:53.387291Z","shell.execute_reply.started":"2022-05-03T16:05:53.378039Z","shell.execute_reply":"2022-05-03T16:05:53.386305Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"model.forward_mode = 'greedy'\ncondidat_corpus, ref_corpus = predict_with_model(model, valid_iterator, bpe)","metadata":{"id":"OLEooAeIcsr6","execution":{"iopub.status.busy":"2022-05-03T16:05:54.636268Z","iopub.execute_input":"2022-05-03T16:05:54.636737Z","iopub.status.idle":"2022-05-03T16:08:15.261845Z","shell.execute_reply.started":"2022-05-03T16:05:54.636703Z","shell.execute_reply":"2022-05-03T16:08:15.261124Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"bleu_score(condidat_corpus, ref_corpus, max_n=3, weights=[0.34, 0.33, 0.33])","metadata":{"id":"uV2cvKHXfSbh","outputId":"d296a5ce-fcde-411f-baff-b85153e30e00","execution":{"iopub.status.busy":"2022-05-03T16:08:23.805919Z","iopub.execute_input":"2022-05-03T16:08:23.806610Z","iopub.status.idle":"2022-05-03T16:08:27.840896Z","shell.execute_reply.started":"2022-05-03T16:08:23.806573Z","shell.execute_reply":"2022-05-03T16:08:27.840157Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"0.10517405718564987"},"metadata":{}}]},{"cell_type":"code","source":"for i in range(10):\n    print(' '. join(ref_corpus[i][0]))\n    print(' '.join(condidat_corpus[i]))\n    print('')\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-03T16:08:33.394450Z","iopub.execute_input":"2022-05-03T16:08:33.394713Z","iopub.status.idle":"2022-05-03T16:08:33.404613Z","shell.execute_reply.started":"2022-05-03T16:08:33.394673Z","shell.execute_reply":"2022-05-03T16:08:33.403944Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"nonconvex proximal splitting: batch and incremental algorithms\nglobal optimization of nonconvex composite optimization and\n\na time-varying shared frailty model with application to infectious diseases\na parametric model for network analysis with applications in network epidemiology\n\nempirical quantile clts for time dependent data\nempirical quantile processes for random measures of a stochastic process for\n\nasymptotic normality of the quasi maximum likelihood estimator for multidimensional causal processes\nquasi maximum likelihood estimation for multidimensional causal processes processes\n\nmulti-reference video coding using stillness detection\ngroup coding for classification of video and\n\nmicrobial mutualism at a distance: the role of geometry in diffusive exchanges\nthe role of competition in a model of microbial communities during the development of a species\n\nvisualization of gene expression information within the context of the mouse anatomy\nvisualizations of the atlas and sunspot areas using visualizations analysis analysis using\n\na nonequilibrium-potential approach to competition in neural populations\nthe role of memory in biological networks in the analysis of neural networks:\n\na review of mean-shift algorithms for clustering\nclustering signals using the mean curvature of signals and\n\nsparse functional identification of complex cells from spike times and the decoding of visual stimuli\nidentification of complex and decoding of complex cells with complex signals with\n\n","output_type":"stream"}]},{"cell_type":"code","source":"submission_data = pd.read_csv('/kaggle/input/title-generation/test.csv')\nabstracts = submission_data['abstract'].values\ntest_iter = [(a, 'a') for a in abstracts]\ntest_dataset = Sec2SecDataset( test_iter, text_transform, PAD_IDX, ln_pair = ln_pair)\ntest_iterator = DataLoader(test_dataset, batch_size=30, collate_fn = test_dataset.pad_collate_fn)\n\ntest_preds, _ = predict_with_model(model, test_iterator, bpe)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:51:42.027052Z","iopub.execute_input":"2022-04-27T18:51:42.027333Z","iopub.status.idle":"2022-04-27T18:51:44.471241Z","shell.execute_reply.started":"2022-04-27T18:51:42.027276Z","shell.execute_reply":"2022-04-27T18:51:44.470457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntitles = []\nfor t_pred in test_preds:\n\n    #title, _ = translate_sentence(model, abstract.split())\n    titles.append(' '.join(t_pred).replace('<unk>', ''))\n    \nsubmission_df = pd.DataFrame({'abstract': abstracts, 'title': titles})\nsubmission_df.to_csv('predicted_titles.csv', index=False)","metadata":{"id":"LYNVOFDbcKg3","execution":{"iopub.status.busy":"2022-04-27T18:51:45.375423Z","iopub.execute_input":"2022-04-27T18:51:45.375942Z","iopub.status.idle":"2022-04-27T18:51:45.451678Z","shell.execute_reply.started":"2022-04-27T18:51:45.375898Z","shell.execute_reply":"2022-04-27T18:51:45.449352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string\nfrom nltk.util import ngrams\nimport numpy as np\nimport pandas as pd\nimport pickle\n\n\ndef generate_csv(input_file='predicted_titles.csv',\n                 output_file='submission.csv',\n                 voc_file='/kaggle/input/title-generation/vocs.pkl'):\n    '''\n    Generates file in format required for submitting result to Kaggle\n    \n    Parameters:\n        input_file (str) : path to csv file with your predicted titles.\n                           Should have two fields: abstract and title\n        output_file (str) : path to output submission file\n        voc_file (str) : path to voc.pkl file\n    '''\n    data = pd.read_csv(input_file)\n    with open(voc_file, 'rb') as voc_file:\n        vocs = pickle.load(voc_file)\n\n    with open(output_file, 'w') as res_file:\n        res_file.write('Id,Predict\\n')\n        \n    output_idx = 0\n    for row_idx, row in data.iterrows():\n        try:\n            trg = row['title']\n            trg = trg.translate(str.maketrans('', '', string.punctuation)).lower().split()\n            trg.extend(['_'.join(ngram) for ngram in list(ngrams(trg, 2)) + list(ngrams(trg, 3))])\n\n            VOCAB_stoi = vocs[row_idx]\n            trg_intersection = set(VOCAB_stoi.keys()).intersection(set(trg))\n            trg_vec = np.zeros(len(VOCAB_stoi))    \n\n            for word in trg_intersection:\n                trg_vec[VOCAB_stoi[word]] = 1\n\n            with open(output_file, 'a') as res_file:\n                for is_word in trg_vec:\n                    res_file.write('{0},{1}\\n'.format(output_idx, int(is_word)))\n                    output_idx += 1\n        except:\n            continue\n\n\ngenerate_csv()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:51:46.755312Z","iopub.execute_input":"2022-04-27T18:51:46.755863Z","iopub.status.idle":"2022-04-27T18:51:47.511943Z","shell.execute_reply.started":"2022-04-27T18:51:46.755824Z","shell.execute_reply":"2022-04-27T18:51:47.511213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}