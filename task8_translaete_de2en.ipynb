{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtemNechaev/stepik_nnets/blob/main/task8_translaete_de2en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lytUO5mn9enL"
      },
      "source": [
        "# Генерация кода по вопросам со StackOverflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9fCoAc39enT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "043abe89-25cb-41ec-fa0e-17856bd30ea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'stepik-dl-nlp' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle,\n",
        "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
        "\n",
        "!git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && !pip install -r stepik-dl-nlp/requirements.txt\n",
        "import sys; sys.path.append('./stepik-dl-nlp')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pickle\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open('drive/MyDrive/de_en_vocab.pickle', 'rb') as f:\n",
        "  de_en_vocab = pickle.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnkLNTFr1iSO",
        "outputId": "1fd4a68f-db2d-4228-d3de-7b2c7608a3e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy deep-translator\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmgOOdMD3AmR",
        "outputId": "e84a6d89-b61b-474c-d74e-36ca9e2a0185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.2.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting deep-translator\n",
            "  Downloading deep_translator-1.8.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.5)\n",
            "Collecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n",
            "\u001b[K     |████████████████████████████████| 653 kB 54.3 MB/s \n",
            "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 31.4 MB/s \n",
            "\u001b[?25hCollecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 67.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Collecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.0)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 13.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Collecting beautifulsoup4<5.0.0,>=4.9.1\n",
            "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, beautifulsoup4, spacy, deep-translator\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed beautifulsoup4-4.10.0 catalogue-2.0.7 deep-translator-1.8.1 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 spacy-3.2.3 spacy-legacy-3.0.9 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.15 typer-0.4.0\n",
            "Collecting en-core-web-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.2.0) (3.2.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.15)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.63.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.21.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Collecting de-core-news-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.2.0/de_core_news_sm-3.2.0-py3-none-any.whl (19.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.1 MB 204 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from de-core-news-sm==3.2.0) (3.2.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.0.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (8.0.15)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.9.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.21.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (4.63.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.0.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->de-core-news-sm==3.2.0) (2.0.1)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dneov4I9enW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "from torchtext.datasets import  Multi30k\n",
        "from collections import OrderedDict, Counter\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator, GloVe\n",
        "from torchtext.datasets import Multi30k\n",
        "from typing import Iterable, List\n",
        "#from torchtext.data import Field, BucketIterator\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import spacy\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "import zipfile\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LonnFFNd9enX"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "ENC_EMB_DIM = 100\n",
        "DEC_EMB_DIM = 128\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'http://vectors.nlpl.eu/repository/20/45.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8ckWeY6EeVC",
        "outputId": "6ecd178d-5c8f-4955-a8d8-93dfdfa68aae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-27 16:54:45--  http://vectors.nlpl.eu/repository/20/45.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.181\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.181|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3764660264 (3.5G) [application/zip]\n",
            "Saving to: ‘45.zip’\n",
            "\n",
            "45.zip              100%[===================>]   3.51G  10.3MB/s    in 5m 57s  \n",
            "\n",
            "2022-03-27 17:00:43 (10.1 MB/s) - ‘45.zip’ saved [3764660264/3764660264]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir de_vectors\n",
        "with zipfile.ZipFile('45.zip', 'r') as zf:\n",
        "  zf.extractall('de_vectors')\n",
        "\n",
        "w2v_de = gensim.models.KeyedVectors.load_word2vec_format('de_vectors/model.txt',binary=False, unicode_errors='replace')"
      ],
      "metadata": {
        "id": "FRMwZKzcFJOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#import dlnlputils\n",
        "#from dlnlputils.data import BeamGenerator\n",
        "\n",
        "SRC_LANGUAGE = 'de'\n",
        "TGT_LANGUAGE = 'en'\n",
        "\n",
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}\n",
        "\n",
        "\n",
        "# Create source and target language tokenizer. Make sure to install the dependencies.\n",
        "\n",
        "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
        "\n",
        "\n",
        "\n",
        "to_src = GoogleTranslator(source='english', target='german')\n",
        "to_trg = GoogleTranslator(source='german', target='english')\n",
        "\n",
        "\n",
        "# helper function to yield list of tokens\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform[language](data_sample[language_index[language]].lower())\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    # Training data Iterator\n",
        "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    # Create torchtext's Vocab object\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=1,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True)\n",
        "\n",
        "# Set UNK_IDX as the default index. This index is returned when the token is not found.\n",
        "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary.\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "  vocab_transform[ln].set_default_index(UNK_IDX)\n"
      ],
      "metadata": {
        "id": "Kc8Of-j_Qr6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c934679-6884-4866-dcf1-1decc58d464c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.21M/1.21M [00:01<00:00, 642kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k17tpfFWWtNz",
        "outputId": "149a9270-9bb2-4a04-d902-5fa23c70576c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "src_to_trg = torch.zeros(len(vocab_transform[SRC_LANGUAGE]), dtype=torch.long, )\n",
        "with open('drive/MyDrive/de_en_vocab.pickle', 'rb') as f:\n",
        "  de_en_vocab = pickle.load(f)\n",
        "\n",
        "de_emb_weights = torch.zeros((len(vocab_transform[SRC_LANGUAGE]), ENC_EMB_DIM), dtype=torch.float)\n",
        "\n",
        "\n",
        "for src_w, trg_w in de_en_vocab.items():\n",
        "  src_id = vocab_transform[SRC_LANGUAGE][src_w]\n",
        "  trg_id = vocab_transform[TGT_LANGUAGE][trg_w]\n",
        "  if  (src_id != 0) & (trg_id == 0) & (trg_w != '<unk>') :\n",
        "    vocab_transform[TGT_LANGUAGE].append_token(trg_w)\n",
        "    trg_id = vocab_transform[TGT_LANGUAGE][trg_w]\n",
        "  src_to_trg[src_id] = trg_id\n",
        "\n",
        "  ##load pretrained vectors\n",
        "  #if src_w in w2v_de.vocab:\n",
        "    #embed = w2v_de.get_vector(src_w)\n",
        "    #de_emb_weights[src_id] = torch.FloatTensor(embed)\n",
        "\n",
        "src_to_trg = src_to_trg.to(device)\n",
        "src_to_trg\n"
      ],
      "metadata": {
        "id": "HyOH-OsU8sfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef93f6dc-618f-44bc-d0d8-248256dfa76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1605,    1,    2,  ..., 5882,    0,  103])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(src_to_trg == 0).int().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3yMr6lkNU2X",
        "outputId": "6c26a931-df1b-4518-93e8-288f402190f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(74)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and tgt language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        #src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\").lower()))\n",
        "        #tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\").lower()))\n",
        "        src_batch.append(src_sample)\n",
        "        tgt_batch.append(tgt_sample)\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "  def __init__(self, data, text_transform, src_ln, trg_ln):\n",
        "    super().__init__()\n",
        "    self.tensors = []\n",
        "    for src, trg in data:\n",
        "      self.tensors.append(\n",
        "          (\n",
        "            text_transform[src_ln](src.rstrip(\"\\n\").lower()),\n",
        "            text_transform[trg_ln](trg.rstrip(\"\\n\").lower())\n",
        "          )   \n",
        "      )\n",
        "  def __getitem__(self, idx):\n",
        "    return self.tensors[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.tensors)"
      ],
      "metadata": {
        "id": "bkt8jffTWeGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDDELJJV9ene"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, emb_weights=None):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        if emb_weights != None:\n",
        "          self.embedding.load_state_dict({'weight': emb_weights})\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "        \n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "        \n",
        "        #src = [src sent len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src sent len, batch size, emb dim]\n",
        "        \n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "                     \n",
        "        #packed_outputs is a packed sequence containing all hidden states\n",
        "        #hidden is now from the final non-padded element in the batch\n",
        "            \n",
        "            \n",
        "        #outputs is now a non-packed sequence, all hidden states obtained\n",
        "        #  when the input is a pad token are all zeros\n",
        "            \n",
        "        #outputs = [sent len, batch size, hid dim * num directions]\n",
        "        #hidden = [n layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        #outputs are always from the last layer\n",
        "        \n",
        "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
        "        \n",
        "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
        "        #  encoder RNNs fed through a linear layer\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        #outputs = [sent len, batch size, enc hid dim * 2]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        \n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nBqtTFlKlcv5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2UdS9Yc9enf"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        \n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Parameter(torch.rand(dec_hid_dim))\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
        "        #mask = [batch size, src sent len]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        #repeat encoder hidden state src_len times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #hidden = [batch size, src sent len, dec hid dim]\n",
        "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
        "        \n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
        "        \n",
        "        #energy = [batch size, src sent len, dec hid dim]\n",
        "                \n",
        "        energy = energy.permute(0, 2, 1)\n",
        "        \n",
        "        #energy = [batch size, dec hid dim, src sent len]\n",
        "        \n",
        "        #v = [dec hid dim]\n",
        "        \n",
        "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
        "        \n",
        "        #v = [batch size, 1, dec hid dim]\n",
        "            \n",
        "        attention = torch.bmm(v, energy).squeeze(1)\n",
        "        \n",
        "        #attention = [batch size, src sent len]\n",
        "        \n",
        "        attention = attention.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        return F.softmax(attention, dim = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBY9VM9g9eng"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.combine = nn.Linear(enc_hid_dim * 2 + emb_dim, enc_hid_dim * 2)\n",
        "        \n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        \n",
        "        self.out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_input, encoder_outputs, mask):\n",
        "             \n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_input = [src sent len, batch size]\n",
        "        #encoder_outputs = [src sent len, batch size, enc hid dim * 2]\n",
        "        #mask = [batch size, src sent len]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        #forwar_trans_embed = self.embedding(src_to_trg[encoder_input])\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        #forwar_trans_embed = [src sent len, batch size, emb dim]\n",
        "\n",
        "        #encoder_outputs = self.combine(torch.cat([encoder_outputs, forwar_trans_embed], dim = -1))\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "                \n",
        "        #a = [batch size, src sent len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        \n",
        "        #a = [batch size, 1, src sent len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #encoder_outputs = [batch size, src sent len, enc hid dim * 2]\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        \n",
        "        #weighted = [batch size, 1, enc hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        \n",
        "        #weighted = [1, batch size, enc hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        \n",
        "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        #output = [sent len, batch size, dec hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
        "        \n",
        "        #sent len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output = [1, batch size, dec hid dim]\n",
        "        #hidden = [1, batch size, dec hid dim]\n",
        "        #this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        output = self.out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        \n",
        "        #output = [bsz, output dim]\n",
        "        \n",
        "        return output, hidden.squeeze(0), a.squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKjmhkYW9eng"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, pad_idx, sos_idx, eos_idx, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.pad_idx = pad_idx\n",
        "        self.sos_idx = sos_idx\n",
        "        self.eos_idx = eos_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def create_mask(self, src):\n",
        "        mask = (src != self.pad_idx).permute(1, 0)\n",
        "        return mask\n",
        "        \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src sent len, batch size]\n",
        "        #src_len = [batch size]\n",
        "        #trg = [trg sent len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "        \n",
        "        if trg is None:\n",
        "            assert teacher_forcing_ratio == 0, \"Must be zero during inference\"\n",
        "            inference = True\n",
        "            trg = torch.zeros((100, src.shape[1])).long().fill_(self.sos_idx).to(src.device)\n",
        "        else:\n",
        "            inference = False\n",
        "            \n",
        "        batch_size = src.shape[1]\n",
        "        max_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #tensor to store attention\n",
        "        attentions = torch.zeros(max_len, batch_size, src.shape[0]).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        output = trg[0,:]\n",
        "        \n",
        "        mask = self.create_mask(src)\n",
        "                \n",
        "        #mask = [batch size, src sent len]\n",
        "                \n",
        "        for t in range(1, max_len):\n",
        "            output, hidden, attention = self.decoder(output, hidden, src, encoder_outputs, mask)\n",
        "            outputs[t] = output\n",
        "            attentions[t] = attention\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "            if inference and output.item() == self.eos_idx:\n",
        "                return outputs[:t], attentions[:t]\n",
        "            \n",
        "        return outputs, attentions\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snch6VGQ9enh"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(vocab_transform['de'])\n",
        "OUTPUT_DIM = len(vocab_transform['en'])\n",
        "\n",
        "ENC_HID_DIM = 100\n",
        "DEC_HID_DIM = 100\n",
        "ENC_DROPOUT = 0.2\n",
        "DEC_DROPOUT = 0.2\n",
        "PAD_IDX = PAD_IDX\n",
        "SOS_IDX = BOS_IDX\n",
        "EOS_IDX = EOS_IDX\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT, emb_weights=None)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, PAD_IDX, SOS_IDX, EOS_IDX, device).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5op5Ok99eni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ffbe734-10a4-4d2e-b779-3ba1e3221cb5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(18670, 100)\n",
              "    (rnn): GRU(100, 100, bidirectional=True)\n",
              "    (fc): Linear(in_features=200, out_features=100, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=300, out_features=100, bias=True)\n",
              "    )\n",
              "    (embedding): Embedding(18147, 128)\n",
              "    (combine): Linear(in_features=328, out_features=200, bias=True)\n",
              "    (rnn): GRU(328, 100)\n",
              "    (out): Linear(in_features=428, out_features=18147, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cp0OEmN9eni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2c1fd50-72c2-4d0f-97da-cf5902a4033d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель содержит 12,341,179 параметров\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Модель содержит {count_parameters(model):,} параметров')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNCTNjc99eni"
      },
      "source": [
        "Then we define our optimizer and criterion. We have already initialized `PAD_IDX` when initializing the model, so we don't need to do it again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFfoCLut9enj"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7Oko8Lz9enj"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "sched = optim.lr_scheduler.ReduceLROnPlateau(optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVeYTtqr9enj"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src, trg = batch\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "        src_len = src.shape[0]\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, attetion = model(src, src_len, trg, 0.4)\n",
        "        \n",
        "        #trg = [trg sent len, batch size]\n",
        "        #output = [trg sent len, batch size, output dim]\n",
        "        \n",
        "        #output = output[1:].view(-1, output.shape[-1])\n",
        "        #trg = trg[1:].view(-1)\n",
        "\n",
        "        output = output[1:].permute(1,2,0)\n",
        "        trg = trg[1:].permute(1,0)\n",
        "        \n",
        "        #trg = [(trg sent len - 1) * batch size]\n",
        "        #output = [(trg sent len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1za2nB89enk"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src, trg = batch\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            src_len = src.shape[0]\n",
        "\n",
        "            output, attention = model(src, src_len, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg sent len, batch size]\n",
        "            #output = [trg sent len, batch size, output dim]\n",
        "\n",
        "            #output = output[1:].view(-1, output.shape[-1])\n",
        "            #trg = trg[1:].view(-1)\n",
        "\n",
        "            output = output[1:].permute(1,2,0)\n",
        "            trg = trg[1:].permute(1,0)\n",
        "\n",
        "            #trg = [(trg sent len - 1) * batch size]\n",
        "            #output = [(trg sent len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkJSQ4z99enk"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "0qCCmsOB9enk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "7d77b315-37a7-4998-bb42-adea937f7b67"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-04ef15132014>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-b7e585695e8e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattetion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#trg = [trg sent len, batch size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-9f7fc1b4b351>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_len, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mattentions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-aa84dbe943c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_input, encoder_outputs, mask)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mweighted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m#output = [bsz, output dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 50\n",
        "CLIP = float('inf')\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "train_dataset = TranslationDataset( train_iter, text_transform, 'de', 'en')\n",
        "train_iterator = DataLoader(train_dataset, batch_size=30, collate_fn = collate_fn)\n",
        "\n",
        "valid_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "val_dataset = TranslationDataset( valid_iter, text_transform, 'de', 'en')\n",
        "valid_iterator = DataLoader(val_dataset, batch_size=30, collate_fn = collate_fn)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    sched.step(valid_loss)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'conala_model_attention_test.pt')\n",
        "    \n",
        "    print(f'Эпоха: {epoch+1:02} | Время: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'Перплексия (обучение): {math.exp(train_loss):7.3f}')\n",
        "    print(f'Перплексия (валидация): {math.exp(valid_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'drive/MyDrive/models/translator.pt')\n",
        "model.load_state_dict(torch.load('drive/MyDrive/models/translator.pt', map_location=device))"
      ],
      "metadata": {
        "id": "TofKSsiMHT-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b8c1133-2842-4bd6-f63a-91ca28d428ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nazwD_k39enk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7047610d-661d-4bc7-9572-f296f533bd55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Перплексия (валидация):  35.475\n"
          ]
        }
      ],
      "source": [
        "test_iter = Multi30k(split='test', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "test_iterator = DataLoader(test_iter, batch_size=128, collate_fn = collate_fn)\n",
        "\n",
        "#model.load_state_dict(torch.load('conala_model_attention_test.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Перплексия (валидация): {math.exp(test_loss):7.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBqZI3iA9enl"
      },
      "source": [
        "## Предсказание кода по вопросу"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD66UA029enl"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(model, sentence):\n",
        "    model.eval()\n",
        "    numericalized = text_transform['de'](sentence) \n",
        "\n",
        "    sentence_length = torch.LongTensor([len(numericalized)]).to(device) \n",
        "    tensor = torch.LongTensor(numericalized).unsqueeze(1).to(device) \n",
        "    translation_tensor_logits, attention = model(tensor, sentence_length, None, 0) \n",
        "    translation_tensor = torch.argmax(translation_tensor_logits.squeeze(1), 1)\n",
        "    translation = vocab_transform[TGT_LANGUAGE].lookup_tokens(list(translation_tensor.cpu().numpy()))\n",
        "    translation, attention = translation[1:], attention[1:]\n",
        "    return translation, attention\n",
        "\n",
        "def beam_search(encoder, decoder, sentence, beam_size = 5, max_len = 20):\n",
        "  \n",
        "  numericalized = text_transform['de'](sentence) \n",
        "\n",
        "  sentence_length = torch.LongTensor([len(numericalized)]).to(device) \n",
        "  src = torch.LongTensor(numericalized).unsqueeze(1).repeat(1, beam_size).to(device) \n",
        "  \n",
        "  encoder_outputs, hidden = encoder(src, sentence_length)  #outputs [sent len, 1, enc hid dim * 2] #hidden = [1, dec hid dim]\n",
        "\n",
        "  mask = (src != PAD_IDX).permute(1, 0) # beam_size x src_len\n",
        "\n",
        "  output = src[0,:] # [beam_size]\n",
        "\n",
        "  last_scores = torch.zeros((beam_size, 1)).to(device)\n",
        "  #tensor to store decoder outputs\n",
        "  outputs = torch.zeros(beam_size, max_len).to(device)\n",
        "        \n",
        "  #tensor to store attention\n",
        "  #attentions = torch.zeros(max_len, beam_size, src.shape[0]).to(device)\n",
        "\n",
        "  for i in range(max_len):\n",
        "    dec_logits, hidden, att = decoder(output, hidden, src, encoder_outputs, mask)\n",
        "    \n",
        "    scores = F.log_softmax(dec_logits,1)\n",
        "    ind = scores.argsort(1, descending=True)\n",
        "    scores = torch.gather(scores, 1, ind)[:,:beam_size]\n",
        "    ind = ind[:,:beam_size]\n",
        "\n",
        "    scores += last_scores\n",
        "    order_scores = scores.flatten().argsort(descending=True)\n",
        "    if i == 0:\n",
        "      output = ind.flatten()[:beam_size]\n",
        "    else:\n",
        "      output = ind.flatten()[order_scores][:beam_size]\n",
        "\n",
        "    beam_ids = torch.div(order_scores[:beam_size], beam_size, rounding_mode='floor')\n",
        "    hidden = hidden[beam_ids]\n",
        "    outputs = outputs[beam_ids]\n",
        "    last_scores = (last_scores[beam_ids] + scores.flatten()[order_scores][:beam_size].unsqueeze(1))/(outputs.count_nonzero(1).unsqueeze(1) + 1) ** 0.5\n",
        "\n",
        "    outputs[:,i] = output\n",
        "  \n",
        "  return outputs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "sent = 'Ich habe einen Hund'\n",
        "outputs = beam_search(model.encoder, model.decoder, sent.lower(), beam_size = 5, max_len = 20)"
      ],
      "metadata": {
        "id": "Ng-5V79YmhrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(outputs.shape[0]):\n",
        "  text = vocab_transform[TGT_LANGUAGE].lookup_tokens(list(outputs[i].cpu().numpy()))\n",
        "  print(' '.join(text))"
      ],
      "metadata": {
        "id": "iVY4S0Pr4XlI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd08ca03-3c68-4d94-b914-81dac1d5f009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there is a is a a dog . <eos> dog . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "there is a is a dog . <eos> dog . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "there is a dog dog a dog dog . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "there is a dog dog a dog . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "i am has a dog dog dog . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Xx6qwcB9enl"
      },
      "outputs": [],
      "source": [
        "def display_attention(candidate, translation, attention):\n",
        "    \n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    \n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\n",
        "    \n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "   \n",
        "    ax.tick_params(labelsize=15)\n",
        "    ax.set_xticklabels([''] + ['<bos>'] + [t.lower() for t in token_transform['de'](candidate)] + ['<eos>'], \n",
        "                       rotation=45)\n",
        "    ax.set_yticklabels([''] + translation)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "train_iter = list(train_iter)"
      ],
      "metadata": {
        "id": "wCfh_RXjggh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWrm-fGE9enl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed9e8c24-4704-47a1-f369-f01f208032e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = Ein schickes Mädchen spricht mit dem Handy während sie langsam die Straße entlangschwebt.\n",
            "\n",
            "trg = A trendy girl talking on her cellphone while gliding slowly down the street.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example_idx = 7\n",
        "\n",
        "src = train_iter[example_idx][0]\n",
        "trg = train_iter[example_idx][1]\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = beam_search(model.encoder, model.decoder, src.lower(), beam_size = 5, max_len = 20)\n",
        "for i in range(outputs.shape[0]):\n",
        "  text = vocab_transform[TGT_LANGUAGE].lookup_tokens(list(outputs[i].cpu().numpy()))\n",
        "  print(' '.join(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qe77TJD5jTd",
        "outputId": "415c43d8-706d-4d87-a7b2-a752c617c98d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there a young girl talking to cellphone while she walks down the street . <eos> street . <eos> <eos> <eos>\n",
            "a young girl talking to cellphone while she walks down the street . <eos> street . <eos> <eos> <eos> <eos>\n",
            "a young girl talking to cellphone while she walks down down the street . <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "a young girl talks talking to cellphone while she walks down the street . <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "a young girl talking talking to cellphone while she walks down the street . <eos> <eos> <eos> <eos> <eos> <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpdVxjfN9enm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "5f117033-7e66-48f9-8186-3f975b665e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted trg =  a trendy girl talking to her cellphone while the the the the street .\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-cb0ca0eaf66f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predicted trg = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdisplay_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'display_attention' is not defined"
          ]
        }
      ],
      "source": [
        "translation, attention = translate_sentence(model, src.lower())\n",
        "\n",
        "print('predicted trg = ', ' '.join(translation))\n",
        "\n",
        "display_attention(src, translation, attention)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_iter = Multi30k(split='test', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "valid_iter = list(valid_iter)"
      ],
      "metadata": {
        "id": "zGkrmEJpoYAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kqBkP-U9enm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4693ead4-ee96-4862-b3c8-c73fc748f041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src = Zwei Gruppen von Schwimmern waten ins Wasser.\n",
            "\n",
            "trg = Two groups of swimmers wade out.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example_idx = 678\n",
        "\n",
        "src = valid_iter[example_idx][0]\n",
        "trg = valid_iter[example_idx][1]\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = beam_search(model.encoder, model.decoder, src.lower() , beam_size = 5, max_len = 30)\n",
        "for i in range(outputs.shape[0]):\n",
        "  text = vocab_transform[TGT_LANGUAGE].lookup_tokens(list(outputs[i].cpu().numpy()))\n",
        "  print(' '.join(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3NqoJa56u7R",
        "outputId": "2a6eaf7d-ca96-413c-da0d-b6cdae5ad3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there are groups of swimmers swimmers are water into the water . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "three groups of swimmers are water water water . <eos> water . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "three groups of swimmers are water water water . water . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "there are groups of swimmers swimmers are water into water water . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "there are groups of swimmers swimmers are into water water . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6s5msLMx9enm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "3f3507f6-331b-413c-b1c0-1039dfcf3977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted trg =  a girl in a a a a stick with a a .\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "translation, attention = translate_sentence(model, src.lower())\n",
        "\n",
        "print('predicted trg = ', ' '.join(translation))\n",
        "\n",
        "display_attention(src, translation, attention)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiQnPI-r9enm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "ceeec058-aee7-44fc-a0ab-d7902bc84cbe"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-24c3419c09bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
          ]
        }
      ],
      "source": [
        "example_idx = 4\n",
        "\n",
        "src = ' '.join(vars(test_data.examples[example_idx])['src'])\n",
        "trg = ' '.join(vars(test_data.examples[example_idx])['trg'])\n",
        "\n",
        "print(f'src = {src}')\n",
        "print(f'trg = {trg}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpwUp7iF9enm"
      },
      "outputs": [],
      "source": [
        "translation, attention = translate_sentence(model, src)\n",
        "\n",
        "print('predicted trg = ', ''.join(translation))\n",
        "\n",
        "display_attention(src, translation, attention)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "task8_translaete_de2en",
      "provenance": [],
      "collapsed_sections": [
        "RBqZI3iA9enl"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}