{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtemNechaev/stepik_nnets/blob/main/task9_bert_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNKaJz5j_ylj"
      },
      "source": [
        "# Определение эмоциональной окраски твитов с помощью BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCaXJjHp-uQy"
      },
      "outputs": [],
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle,\n",
        "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
        "\n",
        "# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
        "# import sys; sys.path.append('./stepik-dl-nlp')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "## Установка библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "outputId": "553e9ab6-dd8d-45d4-deae-30a8eeea3ff4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 176 kB 12.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.10.0+cu111)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.32-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 30.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 45.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.63.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.21.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 36.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.10.0.2)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting botocore<1.25.0,>=1.24.32\n",
            "  Downloading botocore-1.24.32-py3-none-any.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 38.7 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.32->boto3->pytorch-transformers) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.32->boto3->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2021.10.8)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 53.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.1.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.21.32 botocore-1.24.32 jmespath-1.0.0 pytorch-transformers-1.2.0 s3transfer-0.5.2 sacremoses-0.0.49 sentencepiece-0.1.96 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Ok002ceNB8E7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.datasets import IMDB\n",
        "#from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        "from pytorch_transformers import AdamW, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "outputId": "206bac08-8a29-4ddd-9871-9f282177776c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla K80\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device == 'cpu':\n",
        "    print('cpu')\n",
        "else:\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "## Загрузка данных\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = IMDB(split='train')\n",
        "test_iter = IMDB(split='test')\n",
        "\n",
        "train_labels, train_texts = zip(*train_iter)\n",
        "test_labels, test_texts = zip(*test_iter)"
      ],
      "metadata": {
        "id": "EBUvTriQOBFT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(train_labels)"
      ],
      "metadata": {
        "id": "Q2ckFHLa5hwm",
        "outputId": "529e1a2a-a694-47da-b9ad-8f1cbba445e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg', 'pos'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label2id = {'neg': 0, 'pos': 1}"
      ],
      "metadata": {
        "id": "hL_9HjS56Eht"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#del punct\n",
        "\n",
        "\n",
        "# add [cls] and [sep] tokens\n",
        "#train_texts = ['[CLS] ' + t + ' [SEP]' for t in train_texts]\n",
        "#test_texts = ['[CLS] ' + t + ' [SEP]' for t in test_texts]\n",
        "\n",
        "train_labels = [label2id[l] for l in train_labels]\n",
        "test_labels = [label2id[l] for l in test_labels]\n"
      ],
      "metadata": {
        "id": "GOcr0-q9S_rb"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "## Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Z474sSC6oe7A",
        "outputId": "9c0e975d-f8ad-4876-df52-aaf37d9ba8cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (718 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (974 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (867 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1106 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (823 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (752 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (985 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (991 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (944 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (713 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1406 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1523 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (946 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (865 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1017 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (770 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (994 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1277 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1005 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (961 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (798 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (942 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (702 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1355 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (823 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (770 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (846 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (850 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1681 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (872 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1543 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (946 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (858 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1015 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (910 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1405 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (809 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (798 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (890 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (773 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1023 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (772 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (912 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (782 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1680 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (729 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (770 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (756 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (770 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (891 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (849 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1385 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (796 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (961 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (773 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (743 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (897 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (930 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2164 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2100 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (889 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1022 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1453 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1399 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (821 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1007 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (848 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (893 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (901 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1018 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (926 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1451 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (871 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (919 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (946 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (793 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (708 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (948 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1166 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (702 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (920 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (943 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (954 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (905 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (770 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (846 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1081 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1156 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1831 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (937 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (762 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (755 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (762 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (735 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (951 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (798 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (754 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (772 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (989 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (873 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (752 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1002 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1093 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (957 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (825 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1438 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1021 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (745 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (928 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (885 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (879 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (742 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (942 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (702 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (756 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1316 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (942 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1003 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (702 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1021 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (733 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (955 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (804 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (951 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (929 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (887 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (829 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (909 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (862 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (809 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (933 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (811 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (830 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (838 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (821 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (936 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (914 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1001 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (859 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (955 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (991 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (772 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (729 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (974 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (823 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (963 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (773 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (762 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (900 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (927 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1272 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (825 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (735 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (813 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (886 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (809 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (815 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (879 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1334 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (947 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (688 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (940 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1015 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (919 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (863 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1153 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (688 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (899 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (916 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (763 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (900 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (934 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1261 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (789 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (900 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (779 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (708 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1120 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (883 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (852 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (964 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (786 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1284 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (999 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (919 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (858 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1095 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (750 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (757 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (906 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (935 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (813 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (799 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (837 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (850 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1293 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (854 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (781 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (781 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (993 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (853 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (948 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (741 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (799 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (860 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (937 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1231 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (773 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (852 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (974 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (913 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (932 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (997 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1756 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (935 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (845 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1483 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1488 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (718 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (710 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1398 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (782 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1019 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1313 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (984 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (975 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1207 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (824 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1497 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (745 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (885 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (710 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (823 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1848 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (945 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1016 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (799 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1347 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (886 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1451 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (982 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1019 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1394 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (845 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1008 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (849 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (959 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (946 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (963 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (782 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1002 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (837 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (934 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (928 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (781 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (823 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (707 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (729 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (898 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1003 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1358 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (718 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1238 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (779 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (753 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (800 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1435 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (688 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (881 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (886 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (779 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (786 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1478 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (773 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1001 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (788 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (744 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (813 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (774 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (974 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (991 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1611 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (828 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (786 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (926 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (823 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1020 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (966 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (888 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (743 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (735 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (886 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (997 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1235 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (972 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1013 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1077 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (899 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (808 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (804 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (752 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (713 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (827 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (796 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (868 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (675 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (966 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1336 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (828 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1208 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (969 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (969 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1339 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1214 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (947 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (974 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (743 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (897 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1329 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1006 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (893 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (757 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (797 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1327 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (763 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1297 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (738 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (929 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (708 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (749 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (815 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (995 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1008 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (743 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (860 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (891 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (804 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1002 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1089 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1000 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1155 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (906 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (895 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (710 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (793 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (899 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (934 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1391 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (905 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (892 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (920 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (852 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (941 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (733 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (944 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1015 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1493 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1003 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (757 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (936 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1560 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (735 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (755 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (926 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (738 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1500 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (977 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (817 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1228 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (762 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (793 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1466 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (763 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1507 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (926 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (893 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (818 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (941 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1350 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (937 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (967 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (710 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (886 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (956 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1132 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (931 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (881 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (792 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (924 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (774 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (770 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (738 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (815 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (884 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (763 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (927 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1164 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (932 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1252 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (900 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (855 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (797 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (993 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1016 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (750 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (999 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (774 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (981 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (781 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (986 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1075 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (933 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (798 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (797 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1071 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (821 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1233 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (898 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (752 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (755 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1664 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (897 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1014 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (862 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (945 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1161 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (718 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (745 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1426 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1403 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1472 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1104 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (779 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (675 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (891 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (999 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (852 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (965 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (3125 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (871 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (919 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (829 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (939 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (928 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1003 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1330 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (797 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (830 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (986 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (883 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (930 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (919 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (808 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (869 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1687 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (718 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (943 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (967 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (986 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (901 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (781 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1413 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (753 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (868 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (733 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (898 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (813 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (882 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (781 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (867 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1422 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (818 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (825 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (947 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (854 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1124 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (837 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (829 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (868 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2313 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (788 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (981 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1020 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (688 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (928 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (992 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (934 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (770 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (858 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (866 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (772 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1019 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1090 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (937 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (802 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (688 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1114 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (743 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1255 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (813 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (742 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1383 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (830 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (978 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (913 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (830 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1141 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (707 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (860 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (939 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (920 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1021 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (718 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (983 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (859 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (975 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (838 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (850 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (923 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1395 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (815 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (959 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1036 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (745 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1014 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1242 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1016 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (797 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1017 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (931 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (708 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (874 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (702 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (905 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (827 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (895 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2220 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (809 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (754 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1296 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (878 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (849 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (902 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (890 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (846 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1690 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1367 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1317 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (984 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1337 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (900 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2465 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (921 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (808 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (915 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1109 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (883 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1449 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (890 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1315 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1004 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (964 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (792 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (924 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (853 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (983 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (888 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (772 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1322 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (774 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1088 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (818 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (944 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (960 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1140 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (788 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1018 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1346 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (804 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (735 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (788 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (864 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1172 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (914 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (949 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (913 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (886 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1289 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (821 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1158 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (772 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (914 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (947 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (941 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1035 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (906 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1189 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (991 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (984 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (708 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (808 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (707 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (708 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (854 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (893 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (905 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (945 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1008 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (774 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (993 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (895 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (915 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (893 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (895 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (854 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (754 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (875 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (992 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (961 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (959 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1017 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (967 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (952 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (969 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (765 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (803 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (905 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (993 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1014 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (867 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (934 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (849 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (944 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (774 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (975 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (957 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (873 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1092 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (756 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (818 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1253 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (837 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (992 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1226 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1210 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (912 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (795 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (713 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (905 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (937 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (742 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (872 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (866 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1182 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (871 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (600 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (945 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (741 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (893 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1068 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (762 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (808 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1023 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (710 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (830 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (800 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (935 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (929 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1340 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (797 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1171 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1957 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (990 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (998 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1323 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (996 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (936 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (910 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1062 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (863 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (799 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (744 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (713 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1009 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (999 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (802 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (806 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (951 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (983 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (933 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (899 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1010 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (782 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (792 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (919 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (875 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (845 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (849 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (933 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (779 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1064 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (752 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1418 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (738 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1011 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (977 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (688 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1349 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (967 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (763 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1100 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (804 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1320 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1175 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (793 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (854 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (858 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1192 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (909 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (962 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (809 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1364 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (749 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (811 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (847 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (707 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (798 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (939 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (985 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (786 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (813 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (893 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (898 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (882 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (909 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (745 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1265 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1285 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (735 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (811 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (837 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1249 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1018 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (849 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1007 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (887 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (968 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (865 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1202 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (885 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (750 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (932 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (813 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (817 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (867 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (852 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1082 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (745 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (824 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (849 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (718 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (887 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (864 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (885 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (770 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (947 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (710 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1290 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (928 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (814 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (854 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (2130 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (850 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1206 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (690 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (762 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (941 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (826 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (802 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (688 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (927 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1357 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (761 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1552 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (896 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (750 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (957 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (786 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (871 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (708 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (688 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (948 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (610 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (697 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (808 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1053 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1305 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (818 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (847 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (810 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (786 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (772 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (943 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1080 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (763 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1374 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (692 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1401 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (869 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1073 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (878 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1003 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (916 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (879 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (873 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1241 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (800 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (741 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (957 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (869 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1002 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (785 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (914 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1163 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1838 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (936 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (743 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1000 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (998 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1098 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1184 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (894 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (779 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (818 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (779 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (992 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (981 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (901 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (963 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (762 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (742 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (733 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (909 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (824 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (885 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (881 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (817 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (881 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (749 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (988 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (901 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (875 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (745 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (851 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (829 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (863 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (889 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1212 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (848 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (831 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (750 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1000 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (959 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (762 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1126 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (749 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (779 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1301 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (699 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (992 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (936 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (888 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1485 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (942 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1353 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1107 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (735 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1079 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1146 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (845 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1446 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (625 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (1010 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 1045, 12524, 1045, 2572, 8025, 1011, 3756, 2013, 2026, 2678, 3573, 2138, 1997, 2035, 1996, 6704, 2008, 5129, 2009, 2043, 2009, 2001, 2034, 2207, 1999, 3476, 1012, 1045, 2036, 2657, 2008, 2012, 2034, 2009, 2001, 8243, 2011, 1057, 1012, 1055, 1012, 8205, 2065, 2009, 2412, 2699, 2000, 4607, 2023, 2406, 1010, 3568, 2108, 1037, 5470, 1997, 3152, 2641, 1000, 6801, 1000, 1045, 2428, 2018, 2000, 2156, 2023, 2005, 2870, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 5436, 2003, 8857, 2105, 1037, 2402, 4467, 3689, 3076, 2315, 14229, 2040, 4122, 2000, 4553, 2673, 2016, 2064, 2055, 2166, 1012, 1999, 3327, 2016, 4122, 2000, 3579, 2014, 3086, 2015, 2000, 2437, 2070, 4066, 1997, 4516, 2006, 2054, 1996, 2779, 25430, 14728, 2245, 2055, 3056, 2576, 3314, 2107, 2004, 1996, 5148, 2162, 1998, 2679, 3314, 1999, 1996, 2142, 2163, 1012, 1999, 2090, 4851, 8801, 1998, 6623, 7939, 4697, 3619, 1997, 8947, 2055, 2037, 10740, 2006, 4331, 1010, 2016, 2038, 3348, 2007, 2014, 3689, 3836, 1010, 19846, 1010, 1998, 2496, 2273, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2054, 8563, 2033, 2055, 1045, 2572, 8025, 1011, 3756, 2003, 2008, 2871, 2086, 3283, 1010, 2023, 2001, 2641, 26932, 1012, 2428, 1010, 1996, 3348, 1998, 16371, 25469, 5019, 2024, 2261, 1998, 2521, 2090, 1010, 2130, 2059, 2009, 1005, 1055, 2025, 2915, 2066, 2070, 10036, 2135, 2081, 22555, 2080, 1012, 2096, 2026, 2406, 3549, 2568, 2424, 2009, 16880, 1010, 1999, 4507, 3348, 1998, 16371, 25469, 2024, 1037, 2350, 18785, 1999, 4467, 5988, 1012, 2130, 13749, 7849, 24544, 1010, 15835, 2037, 3437, 2000, 2204, 2214, 2879, 2198, 4811, 1010, 2018, 3348, 5019, 1999, 2010, 3152, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 2079, 4012, 3549, 2094, 1996, 16587, 2005, 1996, 2755, 2008, 2151, 3348, 3491, 1999, 1996, 2143, 2003, 3491, 2005, 6018, 5682, 2738, 2084, 2074, 2000, 5213, 2111, 1998, 2191, 2769, 2000, 2022, 3491, 1999, 26932, 12370, 1999, 2637, 1012, 1045, 2572, 8025, 1011, 3756, 2003, 1037, 2204, 2143, 2005, 3087, 5782, 2000, 2817, 1996, 6240, 1998, 14629, 1006, 2053, 26136, 3832, 1007, 1997, 4467, 5988, 1012, 2021, 2428, 1010, 2023, 2143, 2987, 1005, 1056, 2031, 2172, 1997, 1037, 5436, 1012, 102]\n"
          ]
        }
      ],
      "source": [
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "input_ids = [tokenizer.encode(sent,  add_special_tokens=True) for sent in train_texts]\n",
        "print (input_ids[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87_kXUeT2-br"
      },
      "source": [
        "BERTу нужно предоставить специальный формат входных данных.\n",
        "\n",
        "\n",
        "- **input ids**: последовательность чисел, отождествляющих каждый токен с его номером в словаре.\n",
        "- **labels**: вектор из нулей и единиц. В нашем случае нули обозначают негативную эмоциональную окраску, единицы - положительную.\n",
        "- **segment mask**: (необязательно) последовательность нулей и единиц, которая показывает, состоит ли входной текст из одного или двух предложений. Для случая одного предложения получится вектор из одних нулей. Для двух: <length_of_sent_1> нулей и <length_of_sent_2> единиц.\n",
        "- **attention mask**: (необязательно) последовательность нулей и единиц, где единицы обозначают токены предложения, нули - паддинг."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Cp9BPRd1tMIo"
      },
      "outputs": [],
      "source": [
        "\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=512,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        ")\n",
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "aFbE-UHvsb7-"
      },
      "outputs": [],
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
        "    input_ids, train_labels, \n",
        "    random_state=42,\n",
        "    test_size=0.1\n",
        ")\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(\n",
        "    attention_masks,\n",
        "    input_ids,\n",
        "    random_state=42,\n",
        "    test_size=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "metadata": {
        "id": "LGTWoo-fTmRJ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "outputs": [],
      "source": [
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    sampler=RandomSampler(train_data),\n",
        "    batch_size=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "_R-JDIQP-uQ-"
      },
      "outputs": [],
      "source": [
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_dataloader = DataLoader(\n",
        "    validation_data,\n",
        "    sampler=SequentialSampler(validation_data),\n",
        "    batch_size=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNl8khAhPYju"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91oLqxUe-uQ-"
      },
      "source": [
        "Загружаем [BertForSequenceClassification](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py#L1129):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "JEtCur1z-uQ-"
      },
      "outputs": [],
      "source": [
        "from pytorch_transformers import AdamW, BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiYqLODf-uQ-"
      },
      "source": [
        "Аналогичные модели есть и для других задач:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "hzrfi58p-uQ_"
      },
      "outputs": [],
      "source": [
        "from pytorch_transformers import BertForQuestionAnswering, BertForTokenClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFsCTp_mporB"
      },
      "outputs": [],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "QxSMw0FrptiL"
      },
      "outputs": [],
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "outputId": "54214987-855e-4e28-904a-65d08593a12d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-f08ce431f2f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtrain_loss_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, labels, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    961\u001b[0m                 position_ids=None, head_mask=None):\n\u001b[1;32m    962\u001b[0m         outputs = self.bert(input_ids, position_ids=position_ids, token_type_ids=token_type_ids,\n\u001b[0;32m--> 963\u001b[0;31m                             attention_mask=attention_mask, head_mask=head_mask)\n\u001b[0m\u001b[1;32m    964\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    708\u001b[0m         encoder_outputs = self.encoder(embedding_output,\n\u001b[1;32m    709\u001b[0m                                        \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                                        head_mask=head_mask)\n\u001b[0m\u001b[1;32m    711\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mattention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mself_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;31m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 11.17 GiB total capacity; 10.53 GiB already allocated; 9.81 MiB free; 10.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# Будем сохранять loss во время обучения\n",
        "# и рисовать график в режиме реального времени\n",
        "train_loss_set = []\n",
        "train_loss = 0\n",
        "\n",
        "\n",
        "# Обучение\n",
        "# Переводим модель в training mode\n",
        "model.train()\n",
        "\n",
        "\n",
        "for step, batch in enumerate(train_dataloader):\n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # если не сделать .zero_grad(), градиенты будут накапливаться\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "\n",
        "    train_loss_set.append(loss[0].item())  \n",
        "    \n",
        "    # Backward pass\n",
        "    loss[0].backward()\n",
        "    \n",
        "    # Обновляем параметры и делаем шаг используя посчитанные градиенты\n",
        "    optimizer.step()\n",
        "\n",
        "    # Обновляем loss\n",
        "    train_loss += loss[0].item()\n",
        "    \n",
        "    # Рисуем график\n",
        "    clear_output(True)\n",
        "    plt.plot(train_loss_set)\n",
        "    plt.title(\"Training loss\")\n",
        "    plt.xlabel(\"Batch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "    \n",
        "print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))\n",
        "\n",
        "\n",
        "# Валидация\n",
        "# Переводим модель в evaluation mode\n",
        "model.eval()\n",
        "\n",
        "valid_preds, valid_labels = [], []\n",
        "\n",
        "for batch in validation_dataloader:   \n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
        "    # Это ускорит процесс предсказания меток для валидационных данных.\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    batch_preds = np.argmax(logits, axis=1)\n",
        "    batch_labels = np.concatenate(label_ids)     \n",
        "    valid_preds.extend(batch_preds)\n",
        "    valid_labels.extend(batch_labels)\n",
        "\n",
        "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
        "    accuracy_score(valid_labels, valid_preds) * 100\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHl32IXG-uRA"
      },
      "outputs": [],
      "source": [
        "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
        "    accuracy_score(valid_labels, valid_preds) * 100\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "# Оценка качества на отложенной выборке"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAN0LZBOOPVh"
      },
      "outputs": [],
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in test_sentences]\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=100,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVUVMhQQ-uRA"
      },
      "outputs": [],
      "source": [
        "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(test_gt)\n",
        "\n",
        "prediction_data = TensorDataset(\n",
        "    prediction_inputs,\n",
        "    prediction_masks,\n",
        "    prediction_labels\n",
        ")\n",
        "\n",
        "prediction_dataloader = DataLoader(\n",
        "    prediction_data, \n",
        "    sampler=SequentialSampler(prediction_data),\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hba10sXR7Xi6"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "test_preds, test_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Распаковываем данные из dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
        "    # Это ускорит процесс предсказания меток для тестовых данных.\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
        "    logits = logits[0].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Сохраняем предсказанные классы и ground truth\n",
        "    batch_preds = np.argmax(logits, axis=1)\n",
        "    batch_labels = np.concatenate(label_ids)  \n",
        "    test_preds.extend(batch_preds)\n",
        "    test_labels.extend(batch_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTR2dmGQ-uRB"
      },
      "outputs": [],
      "source": [
        "acc_score = accuracy_score(test_labels, test_preds)\n",
        "print('Процент правильных предсказаний на отложенной выборке составил: {0:.2f}%'.format(\n",
        "    acc_score*100\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxVv6MrH-uRB"
      },
      "outputs": [],
      "source": [
        "print('Неправильных предсказаний: {0}/{1}'.format(\n",
        "    sum(test_labels != test_preds),\n",
        "    len(test_labels)\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7my0s6O-uRB"
      },
      "source": [
        "### Домашнее задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vvy_bo0z-uRB"
      },
      "source": [
        "Скачайте датасет с отзывами на фильмы. Например, используйте датасет [IMDB Dataset of 50K Movie Reviews](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC7UiWve-uRB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('datasets/bert_sentiment_analysis/homework/IMDB_Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TOlUoj--uRC",
        "outputId": "ca5c3b1c-8e8d-41a7-929a-079f58216ef4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq4tsSHw-uRC"
      },
      "source": [
        "Используйте для дообучения BERT датасет IMDB. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG39RwuA-uRD"
      },
      "source": [
        "Ответьте на вопросы:\n",
        "1. удалось ли достичь такого же accuracy (98\\%) при использовании IMDB датасета?\n",
        "2. удалось ли получить хорошее качество классификации всего за одну эпоху?\n",
        "3. подумайте, в чем может быть причина различий в дообучении одной и той же модели на разных датасетах\n",
        "    - Внимательно изучите датасет с русскими твитами. В чем его особенности? Нет ли явных паттернов или ключевых слов, которые однозначно определяют сентимент твита?\n",
        "    - Попробуйте удалить пунктуацию из датасета с русскими твитами и перезапустите дообучение модели. Изменилось ли итоговое качество работы модели? Почему?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFTFtlqB-uRD"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "BERT Fine-Tuning Sentence Classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}