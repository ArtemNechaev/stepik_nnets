{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtemNechaev/stepik_nnets/blob/main/task9_bert_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNKaJz5j_ylj"
      },
      "source": [
        "# Определение эмоциональной окраски отзывов IMDB c помощью BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCaXJjHp-uQy"
      },
      "outputs": [],
      "source": [
        "# Если Вы запускаете ноутбук на colab или kaggle,\n",
        "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
        "\n",
        "# !git clone https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git && pip install -r stepik-dl-nlp/requirements.txt\n",
        "# import sys; sys.path.append('./stepik-dl-nlp')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "## Установка библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "outputId": "a57dddf7-9603-46c8-876e-7cd51d522a0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.21.36)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.63.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.21.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (0.0.49)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (0.1.96)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (0.5.2)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.36 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (1.24.36)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.36->boto3->pytorch-transformers) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.36->boto3->pytorch-transformers) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.36->boto3->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ok002ceNB8E7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.datasets import IMDB\n",
        "#from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "from pytorch_transformers import BertTokenizer, BertConfig\n",
        "from pytorch_transformers import AdamW, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "outputId": "4de18dd5-3bd8-4864-d925-c16adbbf7155",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla K80\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device == 'cpu':\n",
        "    print('cpu')\n",
        "else:\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "## Загрузка данных\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = IMDB(split='train')\n",
        "test_iter = IMDB(split='test')\n",
        "\n",
        "train_labels, train_texts = zip(*train_iter)\n",
        "test_labels, test_texts = zip(*test_iter)\n",
        "set(train_labels)"
      ],
      "metadata": {
        "id": "EBUvTriQOBFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ac138b-a9fa-4b45-ae79-517cb3522343"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg', 'pos'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label2id = {'neg': 0, 'pos': 1}"
      ],
      "metadata": {
        "id": "Q2ckFHLa5hwm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "## Inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87_kXUeT2-br"
      },
      "source": [
        "BERTу нужно предоставить специальный формат входных данных.\n",
        "\n",
        "\n",
        "- **input ids**: последовательность чисел, отождествляющих каждый токен с его номером в словаре.\n",
        "- **labels**: вектор из нулей и единиц. В нашем случае нули обозначают негативную эмоциональную окраску, единицы - положительную.\n",
        "- **segment mask**: (необязательно) последовательность нулей и единиц, которая показывает, состоит ли входной текст из одного или двух предложений. Для случая одного предложения получится вектор из одних нулей. Для двух: <length_of_sent_1> нулей и <length_of_sent_2> единиц.\n",
        "- **attention mask**: (необязательно) последовательность нулей и единиц, где единицы обозначают токены предложения, нули - паддинг."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "R-LWIUMxhoPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(senteses, in_labels, max_sent_len = 200, max_num_subsent = 5):\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "  input_ids, labels, sent_ids = [], [], []\n",
        "  for sent_id, (sent, label) in enumerate(zip(senteses, in_labels)):\n",
        "    tokens = tokenizer.tokenize(sent)\n",
        "    #if len(tokens) > max_sent_len:\n",
        "    labels.append(label2id[label])\n",
        "    sent_ids.append(sent_id)\n",
        "    for i in range(0, max_sent_len*max_num_subsent, max_sent_len):\n",
        "      input_ids.append(['[CLS]'] + tokens[i:i+max_sent_len] + ['[SEP]'])\n",
        "      \n",
        "    #else:\n",
        "      #input_ids.append(['[CLS]'] + tokens + ['[SEP]'])\n",
        "      #labels.append(label2id[label])\n",
        "      #sent_ids.append(sent_id)\n",
        "\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(s) for s in input_ids]\n",
        "  input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=max_sent_len + 2,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        "  )\n",
        "  attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
        "\n",
        "  input_ids = torch.tensor(input_ids).view(-1,max_num_subsent, max_sent_len + 2 )\n",
        "  labels = torch.tensor(labels)\n",
        "  attention_masks = torch.tensor(attention_masks).view(-1,max_num_subsent, max_sent_len + 2 )\n",
        "  sent_ids = torch.tensor(sent_ids)\n",
        "\n",
        "  dataset = TensorDataset(input_ids, attention_masks, labels, sent_ids)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "yUDOZvb5P7uX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data2(senteses, in_labels, max_sent_len = 200, ):\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "  input_ids, labels, sent_ids = [], [], []\n",
        "  for sent_id, (sent, label) in enumerate(zip(senteses, in_labels)):\n",
        "    tokens = tokenizer.tokenize(sent)\n",
        "    if len(tokens) > max_sent_len: \n",
        "      for i in range(0, max_sent_len*(len(tokens)//max_sent_len), max_sent_len):\n",
        "        input_ids.append(['[CLS]'] + tokens[i:i+max_sent_len] + ['[SEP]'])\n",
        "        labels.append(label2id[label])\n",
        "        sent_ids.append(sent_id)  \n",
        "    else:\n",
        "      input_ids.append(['[CLS]'] + tokens + ['[SEP]'])\n",
        "      labels.append(label2id[label])\n",
        "      sent_ids.append(sent_id)\n",
        "\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(s) for s in input_ids]\n",
        "  input_ids = pad_sequences(\n",
        "    input_ids,\n",
        "    maxlen=max_sent_len + 2,\n",
        "    dtype=\"long\",\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        "  )\n",
        "  attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
        "\n",
        "  input_ids = torch.tensor(input_ids)\n",
        "  labels = torch.tensor(labels)\n",
        "  attention_masks = torch.tensor(attention_masks)\n",
        "  \n",
        "  sent_ids = torch.tensor(sent_ids)\n",
        "\n",
        "  dataset = TensorDataset(input_ids, attention_masks, labels, sent_ids)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "LT92Zw1Nlir3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подготовка данных"
      ],
      "metadata": {
        "id": "LTTvVYh7huLw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "outputs": [],
      "source": [
        "train_data = prepare_data2(train_texts, train_labels, max_sent_len = 300,)\n",
        "train_dataloader = DataLoader(\n",
        "    train_data,\n",
        "    sampler=RandomSampler(train_data),\n",
        "    batch_size=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_R-JDIQP-uQ-"
      },
      "outputs": [],
      "source": [
        "validation_data = prepare_data2(test_texts, test_labels, max_sent_len = 300, )\n",
        "validation_dataloader = DataLoader(\n",
        "    validation_data,\n",
        "    sampler=SequentialSampler(validation_data),\n",
        "    batch_size=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNl8khAhPYju"
      },
      "source": [
        "## Модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91oLqxUe-uQ-"
      },
      "source": [
        "Загружаем [BertForSequenceClassification](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/modeling.py#L1129):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JEtCur1z-uQ-"
      },
      "outputs": [],
      "source": [
        "from pytorch_transformers import AdamW, BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.bert = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "    self.loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, b_input_ids, b_input_mask, b_labels, b_sent_ids):\n",
        "    #b_input_ids batch_size x max_len_subsent x max_sent_len\n",
        "    max_len_subsent, max_sent_len = b_input_ids.shape[1], b_input_ids.shape[2]\n",
        "\n",
        "    b_input_ids = b_input_ids.view(-1, max_sent_len) #batch_size * max_len_subsent x max_sent_len\n",
        "    b_input_mask = b_input_mask.view(-1, max_sent_len)\n",
        "    logits = self.bert(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    logits = logits[0].view(-1, max_len_subsent, 2 ).mean(1)\n",
        "    loss = self.loss_fn(logits, b_labels)\n",
        "    if self.training:\n",
        "      loss = self.loss_fn(logits, b_labels)\n",
        "      return logits, loss\n",
        "    else:\n",
        "      return logits, b_labels, b_sent_ids"
      ],
      "metadata": {
        "id": "xL9924ZN3iyi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model2(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.bert = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=50)\n",
        "    self.ln = torch.nn.LayerNorm(50)\n",
        "    self.fc = torch.nn.Linear(50,2)\n",
        "    self.loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, b_input_ids, b_input_mask, b_labels, b_sent_ids):\n",
        "\n",
        "    logits = self.bert(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    logits = self.ln(logits[0])\n",
        "    ind = b_sent_ids.argsort()\n",
        "    logits = logits[ind]\n",
        "    b_sent_ids = b_sent_ids[ind]\n",
        "    b_labels = b_labels[ind]\n",
        "\n",
        "    _ ,counts = b_sent_ids.unique(return_counts=True)\n",
        "    counts = list(counts.cpu().numpy())\n",
        "    ids = [sum(counts[:i]) for i in range(len(counts))]\n",
        "\n",
        "    logits = torch.cat([t.mean(0, keepdim=True) for t in logits.split(counts)], )\n",
        "    b_labels = b_labels[ids]\n",
        "    b_sent_ids = b_sent_ids[ids]\n",
        "\n",
        "    if self.training:\n",
        "      loss = self.loss_fn(logits, b_labels)\n",
        "      return logits, loss\n",
        "    else:\n",
        "      return logits, b_labels, b_sent_ids\n",
        "    \n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "7aFRieL7mB7l"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение"
      ],
      "metadata": {
        "id": "pR6BmPH_hfzQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc354867-bf99-431e-b8ef-11e97ee267ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = Model2()\n",
        "model.cuda()\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "QxSMw0FrptiL"
      },
      "outputs": [],
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "outputId": "c66c25fa-ad00-40ba-9b88-433ac563a281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2887it [1:00:18,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss на обучающей выборке: 0.36402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# Будем сохранять loss во время обучения\n",
        "# и рисовать график в режиме реального времени\n",
        "train_loss_set = []\n",
        "train_loss = 0\n",
        "\n",
        "\n",
        "# Обучение\n",
        "# Переводим модель в training mode\n",
        "model.train()\n",
        "\n",
        "\n",
        "for step, batch in tqdm(enumerate(train_dataloader)):\n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Распаковываем данные из dataloader\n",
        "    #b_input_ids, b_input_mask, b_labels, b_sent_ids = batch\n",
        "    \n",
        "    # если не сделать .zero_grad(), градиенты будут накапливаться\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward pass\n",
        "    logits, loss = model(*batch)\n",
        "\n",
        "    train_loss_set.append(loss.item())  \n",
        "    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    \n",
        "    # Обновляем параметры и делаем шаг используя посчитанные градиенты\n",
        "    optimizer.step()\n",
        "\n",
        "    # Обновляем loss\n",
        "    train_loss += loss.item()\n",
        "    \n",
        "    # Рисуем график\n",
        "    clear_output(True)\n",
        "    plt.plot(train_loss_set)\n",
        "    plt.title(\"Training loss\")\n",
        "    plt.xlabel(\"Batch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "    \n",
        "print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Валидация\n",
        "# Переводим модель в evaluation mode\n",
        "model.eval()\n",
        "\n",
        "valid_preds, valid_labels, valid_sent_ids = [], [], []\n",
        "\n",
        "for batch in tqdm(validation_dataloader):   \n",
        "    # добавляем батч для вычисления на GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Распаковываем данные из dataloader\n",
        "    #b_input_ids, b_input_mask, b_labels, b_sent_ids = batch\n",
        "    \n",
        "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
        "    # Это ускорит процесс предсказания меток для валидационных данных.\n",
        "    with torch.no_grad():\n",
        "        logits, b_labels, b_sent_ids = model(*batch)\n",
        "\n",
        "        preds = logits.argmax(1).cpu().numpy()\n",
        "        label_ids = b_labels.cpu().numpy()\n",
        "        sent_ids = b_sent_ids.cpu().numpy()\n",
        "\n",
        "    #batch_labels = np.concatenate(label_ids)     \n",
        "    valid_preds.extend(preds)\n",
        "    valid_labels.extend(label_ids)\n",
        "    valid_sent_ids.extend(sent_ids)\n",
        "\n",
        "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
        "    accuracy_score(valid_labels, valid_preds) * 100\n",
        "))"
      ],
      "metadata": {
        "id": "uP_6BJq6SbjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbab98c7-bfd5-41f0-fe7f-844bb8c6c512"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2858/2858 [18:28<00:00,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Процент правильных предсказаний на валидационной выборке: 93.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, ind = np.unique(valid_sent_ids, return_index=True)\n",
        "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
        "    accuracy_score(np.array(valid_labels)[ind], np.array(valid_preds)[ind])*100\n",
        "))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKwZZWzI2DKU",
        "outputId": "c17054ef-3789-40df-9737-57b6c0e543d0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Процент правильных предсказаний на валидационной выборке: 93.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "# Вопросы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq4tsSHw-uRC"
      },
      "source": [
        "Используйте для дообучения BERT датасет IMDB. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG39RwuA-uRD"
      },
      "source": [
        "Ответьте на вопросы:\n",
        "1. удалось ли достичь такого же accuracy (98\\%) при использовании IMDB датасета?\n",
        "2. удалось ли получить хорошее качество классификации всего за одну эпоху?\n",
        "3. подумайте, в чем может быть причина различий в дообучении одной и той же модели на разных датасетах\n",
        "    - Внимательно изучите датасет с русскими твитами. В чем его особенности? Нет ли явных паттернов или ключевых слов, которые однозначно определяют сентимент твита?\n",
        "    - Попробуйте удалить пунктуацию из датасета с русскими твитами и перезапустите дообучение модели. Изменилось ли итоговое качество работы модели? Почему?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwk9FJjz7G6L",
        "outputId": "43550f0b-a358-4f5e-f033-7807df51b876"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'drive/MyDrive/models/bert_IMDB_model2.pt')"
      ],
      "metadata": {
        "id": "MPrmYhE67IVw"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XA2qJvV47rhQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "task9_bert_IMDB.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}